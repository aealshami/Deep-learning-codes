{"nbformat":4,"nbformat_minor":0,"metadata":{"coursera":{"course_slug":"neural-networks-deep-learning","graded_item_id":"TSPse","launcher_item_id":"24mxX"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"colab":{"name":"regularized_deepNN_tensorflow.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"WQInL2R-rxRP"},"source":["# Image Application: cat or not?\n","\n","**After this assignment you will be able to:**\n","- Build and apply a deep neural network to supervised learning. \n","- Learn how to do data normalization\n","- learn how to do weight initialization\n","- Learn how to use regularization\n","\n","Let's get started!"]},{"cell_type":"markdown","metadata":{"id":"xys4aQ5UrxRT"},"source":["## 1 - Packages"]},{"cell_type":"markdown","metadata":{"id":"hei_-Ma-tOhR"},"source":["**Exercise**: Please mount your Google drive, and set up your working folder here."]},{"cell_type":"code","metadata":{"id":"_0U8Y54Congl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1644206572152,"user_tz":300,"elapsed":24405,"user":{"displayName":"Ahmad Alshami","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01911245819879647322"}},"outputId":"c4a3a1de-f76e-4cd7-bf28-9b4994033da6"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"ibN88sy3sxy5"},"source":["import os\n","# start your code here\n","os.chdir(\"/content/drive/MyDrive/HW-DL/Homework3\") # change your working folder here\n","# end your code here"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"o9H7MX-2rxRT"},"source":["Let's first import all the packages that you will need during this assignment. \n","- [numpy](https://www.numpy.org/) is the fundamental package for scientific computing with Python.\n","- [matplotlib](http://matplotlib.org) is a library to plot graphs in Python.\n","- [h5py](http://www.h5py.org) is a common package to interact with a dataset that is stored on an H5 file.\n","- [PIL](http://www.pythonware.com/products/pil/) and [scipy](https://www.scipy.org/) are used here to test your model with your own picture at the end.\n","- dnn_app_utils provides the customized functions that will be used in this notebook.\n","- np.random.seed(1) is used to keep all the random function calls consistent. It will help us grade your work."]},{"cell_type":"code","metadata":{"id":"MY54vu0IrxRU"},"source":["import time\n","import numpy as np\n","import tensorflow as tf\n","import h5py\n","import matplotlib.pyplot as plt\n","import dnn_app_utils_v3 as du\n","from skimage.transform import rescale, resize, downscale_local_mean\n","\n","# refresh 'planar_utils' module\n","import imp\n","imp.reload(du)\n","\n","%matplotlib inline\n","plt.rcParams['figure.figsize'] = (5.0, 4.0) # set default size of plots\n","plt.rcParams['image.interpolation'] = 'nearest'\n","plt.rcParams['image.cmap'] = 'gray'\n","\n","%load_ext autoreload\n","%autoreload 2\n","\n","np.random.seed(1)\n","tf.random.set_seed(1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ng-fWoBBrxRW"},"source":["## 2 - Dataset\n","\n","**Problem Statement**: You are given a dataset (\"data.h5\") containing:\n","    - a training set of m_train images labelled as cat (1) or non-cat (0)\n","    - a test set of m_test images labelled as cat and non-cat\n","    - each image is of shape (num_px, num_px, 3) where 3 is for the 3 channels (RGB).\n","\n","Let's get more familiar with the dataset. Load the data by running the cell below.\n","\n","The training input and output are stored in 'train_x_orig' and 'train_y'. The test input and output are stored in 'test_x_orig' and 'test_y'. "]},{"cell_type":"code","metadata":{"id":"JeriZ2MHrxRW"},"source":["train_x_orig, train_y, test_x_orig, test_y, classes = du.load_data()\n","#print(classes)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"B6gdY7eWrxRX"},"source":["The following code will show you an image in the dataset. Feel free to change the index and re-run the cell multiple times to see other images. "]},{"cell_type":"code","metadata":{"id":"GLC4JfABrxRX","colab":{"base_uri":"https://localhost:8080/","height":285},"outputId":"adf9311c-9013-48c8-85e2-d436d3171aa9","executionInfo":{"status":"ok","timestamp":1644206580089,"user_tz":300,"elapsed":574,"user":{"displayName":"Ahmad Alshami","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01911245819879647322"}}},"source":["# Example of a picture\n","index = 200\n","plt.imshow(train_x_orig[index])\n","print(\"y = \" + str(train_y[index,0]) + \". It's a \" + classes[train_y[index,0]].decode(\"utf-8\") +  \" picture.\")\n","#print(train_x_orig[index].shape,train_x_orig[index])"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["y = 1. It's a cat picture.\n"]},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 360x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"8LcmDz99lbsD"},"source":["Let's explore more about the training data. We are curious about the shape of each image and can use 'train_x_orig[index].shape' to expore it. \n","**Exercise**: Can you tell what the pixel number of each image is?"]},{"cell_type":"code","metadata":{"id":"tKIwmFCyrxRY","colab":{"base_uri":"https://localhost:8080/"},"outputId":"aae9a6bf-b4d5-4a9d-bd33-41630cea027b","executionInfo":{"status":"ok","timestamp":1644206580090,"user_tz":300,"elapsed":4,"user":{"displayName":"Ahmad Alshami","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01911245819879647322"}}},"source":["# Explore your dataset \n","image_shape=train_x_orig[index].shape\n","print(\"Each image is of size: \", image_shape)\n","#start your code here\n","num_px=209   # the number of pixels in each column of the image. Hint: The 1st element in image_shape indicates this number?\n","#end your code here\n","print('Number of pixels in each column of the image:', num_px)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Each image is of size:  (64, 64, 3)\n","Number of pixels in each column of the image: 209\n"]}]},{"cell_type":"markdown","metadata":{"id":"SBoQZoWQpBU4"},"source":["We just take a close look at an image of the image set. Now, let's take a look at the whole training set. \n","\n","**Exercise**: The first 4 lines in the following cell print out the shape of the trining images. There are 209 images, and each image has 64 by 64 pixcels and GRB color. \n","\n","Please print out the shape of the test input (stored in `test_x_orig`) and output (stored in `test_y`) data, and tell how many images we have in the test data. "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"79Q7fiuYnP1C","outputId":"2050d5f2-1cd6-47f2-d0db-db7a8757b8b5","executionInfo":{"status":"ok","timestamp":1644206614362,"user_tz":300,"elapsed":277,"user":{"displayName":"Ahmad Alshami","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01911245819879647322"}}},"source":["train_x_shape=train_x_orig.shape\n","m_train = train_x_shape[0]\n","print (\"train_x_orig shape: \",train_x_shape)\n","print (\"Number of training examples: \" ,m_train)\n","# start your code here\n","test_x_shape=test_x_orig.shape\n","test_y_shape=test_y.shape\n","m_test = test_x_shape[0]\n","# end your code here\n","print (train_y.shape)\n","print (\"test_x_orig shape: \" ,test_x_shape)\n","print (\"test_y shape: \" , test_y_shape)\n","print (\"Number of test examples: \" ,m_test)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["train_x_orig shape:  (209, 64, 64, 3)\n","Number of training examples:  209\n","(209, 1)\n","test_x_orig shape:  (50, 64, 64, 3)\n","test_y shape:  (50, 1)\n","Number of test examples:  50\n"]}]},{"cell_type":"markdown","metadata":{"id":"pMoCSiCWrxRY"},"source":["As mentioned in our lecture, you reshape and standardize the images before feeding them to the network. The code is given in the cell below.\n","\n","![alt text](https://drive.google.com/uc?id=12XXwVJpcT-moegSdzejC-W-hD79qDSk9)\n","<caption><center> <u>Figure 1</u>: Image to vector conversion. <br> </center></caption>"]},{"cell_type":"code","metadata":{"id":"nrdXco3grxRY"},"source":["# Reshape the training and test examples \n","train_x_flatten = train_x_orig.reshape(train_x_shape[0], -1)   # The \"-1\" makes reshape flatten the remaining dimensions\n","test_x_flatten = test_x_orig.reshape(test_x_orig.shape[0], -1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vvmsCTJfN_OS"},"source":["Data normalization can help us accelerate the training process. The RGB values of an image are integers in the range of [0,255]. We can normalize the training images to have the feature values between 0 and 1 by using `train_x = train_x_flatten/255.0`.\n","\n","**Exercise**: We normalize the training images using `train_x = train_x_flatten/255.0` in the 1st line. Please normalize the test images to have feature values between 0 and 1."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XpmJC7S8OlGL","outputId":"eb9b261a-05f4-4687-91c3-77c315485a05","executionInfo":{"status":"ok","timestamp":1643597350097,"user_tz":300,"elapsed":145,"user":{"displayName":"Ahmad Alshami","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01911245819879647322"}}},"source":["# Standardize data to have feature values between 0 and 1.\n","train_x = train_x_flatten/255.0\n","\n","#start your code here\n","test_x = test_x_flatten/255.0\n","#end your code here\n","\n","print (\"train_x's shape: \" + str(train_x.shape))\n","print (\"test_x's shape: \" + str(test_x.shape))\n","print (\"train_y's shape: \" + str(train_y.shape))\n","print (\"test_y's shape: \" + str(test_y.shape))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["train_x's shape: (209, 12288)\n","test_x's shape: (50, 12288)\n","train_y's shape: (209, 1)\n","test_y's shape: (50, 1)\n"]}]},{"cell_type":"markdown","metadata":{"id":"4q-yRZNQQBtY"},"source":["###3- Build your neural network ###\n","Now, we are going to use the skills in the first module to build our neural network. \n","\n","Excep the input layer, you can use \n","\n","`tf.keras.layers.Dense(20,activation='relu', \n","                            kernel_initializer='glorot_uniform',\n","                            bias_initializer='zeros')`\n","\n","to build the layers. In this example, we have 20 neurons in this layer, use 'relu' as the activation function, initialize our weight randomly using 'glorot_uniform', and our bias is initialized to be 'zeros'. \n","\n","First, we will need an input layer. How many neurons will you need in the input layer? Hint: how many elements does every training input have?\n","\n","Second, we will build several hidden layers. You are free to choose the number of neurons in every hidden layer. \n","\n","Last, we will build the output layer. How many neurons will you need in the output layer? Which activation function is more suitale in this problem? Hint: how many elements does every training output have? What is the range of the training output?\n"]},{"cell_type":"code","metadata":{"id":"H71UHvjaxREs","colab":{"base_uri":"https://localhost:8080/"},"outputId":"155f35f3-8fef-40e5-d548-240edf4b1d08","executionInfo":{"status":"ok","timestamp":1643597352498,"user_tz":300,"elapsed":182,"user":{"displayName":"Ahmad Alshami","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01911245819879647322"}}},"source":["tf.random.set_seed(1) # we fixed the seed of the random number generator, so every time running this code, we can have the same results.\n","\n","# start your code here\n","cat_model=tf.keras.Sequential([\n","    tf.keras.layers.InputLayer(input_shape=(12288)), # how many elements are there in every training image?\n","    tf.keras.layers.Dense(20,activation='relu', # in layer 1, we will have 20 neurons and use 'relu' as the activation function\n","                            kernel_initializer='glorot_uniform', # we will randomly choose the initial weight using the 'glorot_uniform' method\n","                            bias_initializer='zeros'), # we will initialize all bias to be zeros.\n","                      \n","    #please follow the example of layer 1 to add more hidden layers here. \n","\n","    # End adding hidden layers                    \n","    tf.keras.layers.Dense(1,activation='sigmoid', # how many elements are there in every training output\n","                            kernel_initializer='glorot_uniform',\n","                            bias_initializer='zeros'),\n","])\n","# end your code here\n","cat_model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_9\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_34 (Dense)            (None, 50)                614450    \n","                                                                 \n"," dense_35 (Dense)            (None, 20)                1020      \n","                                                                 \n"," dense_36 (Dense)            (None, 10)                210       \n","                                                                 \n"," dense_37 (Dense)            (None, 1)                 11        \n","                                                                 \n","=================================================================\n","Total params: 615,691\n","Trainable params: 615,691\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","metadata":{"id":"nRMApHybXkD8"},"source":["Now, let's compile the model. When comiling your model, you will need to specify the optimizer, the loss function, and the metrics.\n","\n","For optimizers, the most popular ones are 'Adam' and its derivatives. You can also try 'RMSprop' and 'SGD' to see which one works better for you. You might need adjust the learning rate to acceperate the training process. \n","\n","For loss functions, our problem is a two-class classification problem. The most popular loss function would be 'BinaryCrossentropy'. If this is a multiple-class classification problem, you probably want to try 'CategoricalCrossentropy' or 'SparseCategoricalCrossentropy'. \n","\n","For the metrics, we want to know the accuracy of our model. Therefore, I would recommend 'accuracy'. "]},{"cell_type":"code","metadata":{"id":"R2zh-VWoT7o5"},"source":["# start your code here\n","cat_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),  # Optimizer. Please change 'None' to some meaningful learning rate which is usually <1\n","    # Loss function to minimize\n","    loss=tf.keras.losses.BinaryCrossentropy(),\n","    # List of metrics to monitor\n","    metrics=['accuracy'],\n","                 )\n","# end your code here"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SGSAcJuTZw2C"},"source":["It's time to train. \n","\n","We can plot training history. It can help us to adjust the parameters. \n","\n","If the training loss increases, we may want to decrease the `learning_rate`.\n","\n","If the training loss has large vibration, we may want to decrease the `learning_rate`. \n","\n","If the training loss decreases too slowly, we need to increase `learning_rate`.\n","\n","If the training loss decreases at a good speed, but ends up large, we may want to increase the epoch number. "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"TYZnpHLPVIRY","outputId":"dcbf556c-827b-4157-ce34-ce50b5c16b0a","executionInfo":{"status":"ok","timestamp":1643597439142,"user_tz":300,"elapsed":82919,"user":{"displayName":"Ahmad Alshami","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01911245819879647322"}}},"source":["# start your code here\n","history = cat_model.fit(\n","    train_x, # input data\n","    train_y, # real output data\n","    validation_split=0.1, # this number is usually betwwen 0 and 0.3. It is the portion used as validation data, \n","    epochs=500, # how many iterations do you want to train your model? Your data will be reused to train the model for the number of epochs. I trained 5 min for this model\n",")\n","# end your code here. \n","plt.figure()\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.legend(['loss','val_loss'])"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/500\n","6/6 [==============================] - 1s 39ms/step - loss: 7.3956 - accuracy: 0.5798 - val_loss: 3.5712 - val_accuracy: 0.1905\n","Epoch 2/500\n","6/6 [==============================] - 0s 12ms/step - loss: 2.0293 - accuracy: 0.4734 - val_loss: 3.2125 - val_accuracy: 0.1905\n","Epoch 3/500\n","6/6 [==============================] - 0s 13ms/step - loss: 1.9710 - accuracy: 0.5106 - val_loss: 1.0299 - val_accuracy: 0.3810\n","Epoch 4/500\n","6/6 [==============================] - 0s 14ms/step - loss: 1.0427 - accuracy: 0.5319 - val_loss: 0.6375 - val_accuracy: 0.7619\n","Epoch 5/500\n","6/6 [==============================] - 0s 14ms/step - loss: 0.8244 - accuracy: 0.5638 - val_loss: 0.8154 - val_accuracy: 0.7619\n","Epoch 6/500\n","6/6 [==============================] - 0s 11ms/step - loss: 0.7929 - accuracy: 0.6117 - val_loss: 0.6063 - val_accuracy: 0.7619\n","Epoch 7/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.6353 - accuracy: 0.6596 - val_loss: 0.6085 - val_accuracy: 0.7143\n","Epoch 8/500\n","6/6 [==============================] - 0s 11ms/step - loss: 0.5814 - accuracy: 0.7021 - val_loss: 0.6474 - val_accuracy: 0.5714\n","Epoch 9/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.5605 - accuracy: 0.6809 - val_loss: 0.8970 - val_accuracy: 0.4286\n","Epoch 10/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.6933 - accuracy: 0.6489 - val_loss: 0.8543 - val_accuracy: 0.5238\n","Epoch 11/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.5881 - accuracy: 0.6968 - val_loss: 0.5779 - val_accuracy: 0.7619\n","Epoch 12/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.5460 - accuracy: 0.7553 - val_loss: 0.6117 - val_accuracy: 0.7619\n","Epoch 13/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.6823 - accuracy: 0.6170 - val_loss: 0.6771 - val_accuracy: 0.7619\n","Epoch 14/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.6704 - accuracy: 0.6596 - val_loss: 0.5881 - val_accuracy: 0.7619\n","Epoch 15/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.5074 - accuracy: 0.7340 - val_loss: 0.8563 - val_accuracy: 0.4762\n","Epoch 16/500\n","6/6 [==============================] - 0s 15ms/step - loss: 0.5272 - accuracy: 0.7234 - val_loss: 0.9597 - val_accuracy: 0.4762\n","Epoch 17/500\n","6/6 [==============================] - 0s 14ms/step - loss: 0.5910 - accuracy: 0.7074 - val_loss: 0.9422 - val_accuracy: 0.4286\n","Epoch 18/500\n","6/6 [==============================] - 0s 11ms/step - loss: 0.5962 - accuracy: 0.6543 - val_loss: 0.7239 - val_accuracy: 0.4286\n","Epoch 19/500\n","6/6 [==============================] - 0s 11ms/step - loss: 0.5269 - accuracy: 0.7447 - val_loss: 0.7877 - val_accuracy: 0.4286\n","Epoch 20/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.6118 - accuracy: 0.7074 - val_loss: 0.6574 - val_accuracy: 0.7619\n","Epoch 21/500\n","6/6 [==============================] - 0s 11ms/step - loss: 0.4672 - accuracy: 0.7766 - val_loss: 0.6529 - val_accuracy: 0.5714\n","Epoch 22/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.3897 - accuracy: 0.8511 - val_loss: 0.7192 - val_accuracy: 0.4762\n","Epoch 23/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.3860 - accuracy: 0.8617 - val_loss: 0.6621 - val_accuracy: 0.5238\n","Epoch 24/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.4056 - accuracy: 0.8085 - val_loss: 0.6716 - val_accuracy: 0.5238\n","Epoch 25/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.4199 - accuracy: 0.7926 - val_loss: 0.7038 - val_accuracy: 0.5238\n","Epoch 26/500\n","6/6 [==============================] - 0s 11ms/step - loss: 0.3198 - accuracy: 0.8830 - val_loss: 1.0443 - val_accuracy: 0.4762\n","Epoch 27/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.3937 - accuracy: 0.8085 - val_loss: 1.2462 - val_accuracy: 0.3810\n","Epoch 28/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.3251 - accuracy: 0.8670 - val_loss: 0.8280 - val_accuracy: 0.4762\n","Epoch 29/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.3038 - accuracy: 0.8830 - val_loss: 0.7818 - val_accuracy: 0.7619\n","Epoch 30/500\n","6/6 [==============================] - 0s 11ms/step - loss: 0.4959 - accuracy: 0.7660 - val_loss: 1.1817 - val_accuracy: 0.7619\n","Epoch 31/500\n","6/6 [==============================] - 0s 15ms/step - loss: 0.6705 - accuracy: 0.7128 - val_loss: 1.1492 - val_accuracy: 0.7619\n","Epoch 32/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.6135 - accuracy: 0.7447 - val_loss: 0.8320 - val_accuracy: 0.7619\n","Epoch 33/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.4459 - accuracy: 0.7819 - val_loss: 0.7517 - val_accuracy: 0.6667\n","Epoch 34/500\n","6/6 [==============================] - 0s 11ms/step - loss: 0.3732 - accuracy: 0.8351 - val_loss: 0.9087 - val_accuracy: 0.3810\n","Epoch 35/500\n","6/6 [==============================] - 0s 11ms/step - loss: 0.2824 - accuracy: 0.8936 - val_loss: 0.9192 - val_accuracy: 0.4286\n","Epoch 36/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.2750 - accuracy: 0.9202 - val_loss: 0.8624 - val_accuracy: 0.4762\n","Epoch 37/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.2457 - accuracy: 0.9043 - val_loss: 1.2597 - val_accuracy: 0.3810\n","Epoch 38/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.4036 - accuracy: 0.8191 - val_loss: 1.2330 - val_accuracy: 0.3810\n","Epoch 39/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.2828 - accuracy: 0.8936 - val_loss: 0.9289 - val_accuracy: 0.4286\n","Epoch 40/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.2140 - accuracy: 0.9415 - val_loss: 0.9765 - val_accuracy: 0.4286\n","Epoch 41/500\n","6/6 [==============================] - 0s 14ms/step - loss: 0.2192 - accuracy: 0.9202 - val_loss: 0.9666 - val_accuracy: 0.4286\n","Epoch 42/500\n","6/6 [==============================] - 0s 15ms/step - loss: 0.1912 - accuracy: 0.9628 - val_loss: 0.9568 - val_accuracy: 0.4762\n","Epoch 43/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.1829 - accuracy: 0.9521 - val_loss: 0.9915 - val_accuracy: 0.4762\n","Epoch 44/500\n","6/6 [==============================] - 0s 15ms/step - loss: 0.1650 - accuracy: 0.9468 - val_loss: 0.9502 - val_accuracy: 0.5714\n","Epoch 45/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.1523 - accuracy: 0.9468 - val_loss: 1.1415 - val_accuracy: 0.3810\n","Epoch 46/500\n","6/6 [==============================] - 0s 14ms/step - loss: 0.1631 - accuracy: 0.9628 - val_loss: 1.1572 - val_accuracy: 0.3810\n","Epoch 47/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.1771 - accuracy: 0.9309 - val_loss: 1.2031 - val_accuracy: 0.4286\n","Epoch 48/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.1733 - accuracy: 0.9255 - val_loss: 1.1089 - val_accuracy: 0.3810\n","Epoch 49/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.1413 - accuracy: 0.9521 - val_loss: 1.0369 - val_accuracy: 0.5714\n","Epoch 50/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.1217 - accuracy: 0.9628 - val_loss: 1.1122 - val_accuracy: 0.6190\n","Epoch 51/500\n","6/6 [==============================] - 0s 14ms/step - loss: 0.1044 - accuracy: 0.9681 - val_loss: 1.0931 - val_accuracy: 0.5714\n","Epoch 52/500\n","6/6 [==============================] - 0s 14ms/step - loss: 0.1323 - accuracy: 0.9468 - val_loss: 1.2125 - val_accuracy: 0.4286\n","Epoch 53/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.3577 - accuracy: 0.8245 - val_loss: 1.7421 - val_accuracy: 0.3333\n","Epoch 54/500\n","6/6 [==============================] - 0s 14ms/step - loss: 0.2027 - accuracy: 0.9202 - val_loss: 1.2059 - val_accuracy: 0.4286\n","Epoch 55/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0999 - accuracy: 0.9681 - val_loss: 1.5554 - val_accuracy: 0.3810\n","Epoch 56/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.2357 - accuracy: 0.8936 - val_loss: 1.9887 - val_accuracy: 0.3333\n","Epoch 57/500\n","6/6 [==============================] - 0s 17ms/step - loss: 0.1792 - accuracy: 0.9309 - val_loss: 1.5551 - val_accuracy: 0.2857\n","Epoch 58/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.1650 - accuracy: 0.9362 - val_loss: 1.3352 - val_accuracy: 0.4286\n","Epoch 59/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.1432 - accuracy: 0.9415 - val_loss: 1.3189 - val_accuracy: 0.5238\n","Epoch 60/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.1221 - accuracy: 0.9574 - val_loss: 1.3674 - val_accuracy: 0.4286\n","Epoch 61/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0968 - accuracy: 0.9681 - val_loss: 1.5906 - val_accuracy: 0.4286\n","Epoch 62/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.1590 - accuracy: 0.9362 - val_loss: 1.9394 - val_accuracy: 0.2857\n","Epoch 63/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.3691 - accuracy: 0.8351 - val_loss: 1.7264 - val_accuracy: 0.3810\n","Epoch 64/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.3849 - accuracy: 0.8245 - val_loss: 1.3002 - val_accuracy: 0.3810\n","Epoch 65/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.2074 - accuracy: 0.9255 - val_loss: 1.3740 - val_accuracy: 0.5238\n","Epoch 66/500\n","6/6 [==============================] - 0s 11ms/step - loss: 0.1727 - accuracy: 0.9255 - val_loss: 1.2984 - val_accuracy: 0.4762\n","Epoch 67/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.2490 - accuracy: 0.9043 - val_loss: 1.1139 - val_accuracy: 0.4762\n","Epoch 68/500\n","6/6 [==============================] - 0s 11ms/step - loss: 0.6520 - accuracy: 0.7553 - val_loss: 1.4591 - val_accuracy: 0.4286\n","Epoch 69/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.8470 - accuracy: 0.7553 - val_loss: 1.9853 - val_accuracy: 0.2857\n","Epoch 70/500\n","6/6 [==============================] - 0s 14ms/step - loss: 0.9273 - accuracy: 0.5745 - val_loss: 0.5573 - val_accuracy: 0.8095\n","Epoch 71/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.3808 - accuracy: 0.8457 - val_loss: 0.8097 - val_accuracy: 0.4762\n","Epoch 72/500\n","6/6 [==============================] - 0s 11ms/step - loss: 0.1995 - accuracy: 0.9415 - val_loss: 1.2287 - val_accuracy: 0.5238\n","Epoch 73/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.2185 - accuracy: 0.8989 - val_loss: 1.0698 - val_accuracy: 0.3810\n","Epoch 74/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.1241 - accuracy: 0.9681 - val_loss: 1.2227 - val_accuracy: 0.4286\n","Epoch 75/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.1717 - accuracy: 0.9202 - val_loss: 2.6959 - val_accuracy: 0.2857\n","Epoch 76/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.3124 - accuracy: 0.8723 - val_loss: 2.3292 - val_accuracy: 0.2857\n","Epoch 77/500\n","6/6 [==============================] - 0s 14ms/step - loss: 0.3219 - accuracy: 0.8564 - val_loss: 1.7073 - val_accuracy: 0.3333\n","Epoch 78/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.1727 - accuracy: 0.9362 - val_loss: 1.2608 - val_accuracy: 0.6190\n","Epoch 79/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0918 - accuracy: 0.9734 - val_loss: 1.4145 - val_accuracy: 0.4286\n","Epoch 80/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0661 - accuracy: 0.9681 - val_loss: 1.9661 - val_accuracy: 0.4286\n","Epoch 81/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0767 - accuracy: 0.9734 - val_loss: 2.8346 - val_accuracy: 0.3333\n","Epoch 82/500\n","6/6 [==============================] - 0s 14ms/step - loss: 0.0813 - accuracy: 0.9681 - val_loss: 1.2348 - val_accuracy: 0.4286\n","Epoch 83/500\n","6/6 [==============================] - 0s 14ms/step - loss: 0.0641 - accuracy: 0.9840 - val_loss: 1.4477 - val_accuracy: 0.6667\n","Epoch 84/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.3097 - accuracy: 0.8989 - val_loss: 1.3548 - val_accuracy: 0.6667\n","Epoch 85/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.2887 - accuracy: 0.8883 - val_loss: 0.9907 - val_accuracy: 0.7143\n","Epoch 86/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.5623 - accuracy: 0.8032 - val_loss: 0.7256 - val_accuracy: 0.4286\n","Epoch 87/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.2245 - accuracy: 0.9362 - val_loss: 1.6559 - val_accuracy: 0.5238\n","Epoch 88/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.1324 - accuracy: 0.9468 - val_loss: 1.4100 - val_accuracy: 0.5238\n","Epoch 89/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0518 - accuracy: 1.0000 - val_loss: 1.2386 - val_accuracy: 0.3810\n","Epoch 90/500\n","6/6 [==============================] - 0s 17ms/step - loss: 0.1384 - accuracy: 0.9468 - val_loss: 1.6122 - val_accuracy: 0.3333\n","Epoch 91/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0777 - accuracy: 0.9734 - val_loss: 1.9821 - val_accuracy: 0.5714\n","Epoch 92/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.3097 - accuracy: 0.9096 - val_loss: 2.3480 - val_accuracy: 0.5238\n","Epoch 93/500\n","6/6 [==============================] - 0s 11ms/step - loss: 0.1822 - accuracy: 0.9202 - val_loss: 1.1730 - val_accuracy: 0.4286\n","Epoch 94/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.1535 - accuracy: 0.9574 - val_loss: 1.0731 - val_accuracy: 0.6667\n","Epoch 95/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.1284 - accuracy: 0.9521 - val_loss: 1.2606 - val_accuracy: 0.4762\n","Epoch 96/500\n","6/6 [==============================] - 0s 14ms/step - loss: 0.0726 - accuracy: 0.9787 - val_loss: 1.6496 - val_accuracy: 0.4762\n","Epoch 97/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0445 - accuracy: 0.9947 - val_loss: 1.5998 - val_accuracy: 0.6190\n","Epoch 98/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0749 - accuracy: 0.9628 - val_loss: 1.5147 - val_accuracy: 0.5714\n","Epoch 99/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0412 - accuracy: 0.9787 - val_loss: 1.6163 - val_accuracy: 0.3810\n","Epoch 100/500\n","6/6 [==============================] - 0s 15ms/step - loss: 0.0352 - accuracy: 0.9894 - val_loss: 1.4074 - val_accuracy: 0.5238\n","Epoch 101/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0132 - accuracy: 0.9947 - val_loss: 1.5666 - val_accuracy: 0.4762\n","Epoch 102/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 1.6829 - val_accuracy: 0.5714\n","Epoch 103/500\n","6/6 [==============================] - 0s 14ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 1.7865 - val_accuracy: 0.5238\n","Epoch 104/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 1.8380 - val_accuracy: 0.5238\n","Epoch 105/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 1.8803 - val_accuracy: 0.5238\n","Epoch 106/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.8785 - val_accuracy: 0.5238\n","Epoch 107/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.9002 - val_accuracy: 0.4762\n","Epoch 108/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.8953 - val_accuracy: 0.5238\n","Epoch 109/500\n","6/6 [==============================] - 0s 16ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.9275 - val_accuracy: 0.4762\n","Epoch 110/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.9583 - val_accuracy: 0.4762\n","Epoch 111/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 1.9465 - val_accuracy: 0.4762\n","Epoch 112/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0070 - accuracy: 0.9947 - val_loss: 1.9741 - val_accuracy: 0.4762\n","Epoch 113/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.9901 - val_accuracy: 0.4762\n","Epoch 114/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 2.0817 - val_accuracy: 0.4762\n","Epoch 115/500\n","6/6 [==============================] - 0s 18ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 2.0562 - val_accuracy: 0.5238\n","Epoch 116/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.3340 - val_accuracy: 0.4762\n","Epoch 117/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 2.1770 - val_accuracy: 0.5714\n","Epoch 118/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.3688 - val_accuracy: 0.4762\n","Epoch 119/500\n","6/6 [==============================] - 0s 13ms/step - loss: 8.8432e-04 - accuracy: 1.0000 - val_loss: 2.5210 - val_accuracy: 0.4762\n","Epoch 120/500\n","6/6 [==============================] - 0s 12ms/step - loss: 8.5727e-04 - accuracy: 1.0000 - val_loss: 2.5319 - val_accuracy: 0.4762\n","Epoch 121/500\n","6/6 [==============================] - 0s 14ms/step - loss: 6.1179e-04 - accuracy: 1.0000 - val_loss: 2.5227 - val_accuracy: 0.5238\n","Epoch 122/500\n","6/6 [==============================] - 0s 12ms/step - loss: 5.5878e-04 - accuracy: 1.0000 - val_loss: 2.5414 - val_accuracy: 0.5238\n","Epoch 123/500\n","6/6 [==============================] - 0s 12ms/step - loss: 5.2669e-04 - accuracy: 1.0000 - val_loss: 2.5803 - val_accuracy: 0.5238\n","Epoch 124/500\n","6/6 [==============================] - 0s 13ms/step - loss: 4.8749e-04 - accuracy: 1.0000 - val_loss: 2.6256 - val_accuracy: 0.5238\n","Epoch 125/500\n","6/6 [==============================] - 0s 12ms/step - loss: 4.5456e-04 - accuracy: 1.0000 - val_loss: 2.6628 - val_accuracy: 0.4762\n","Epoch 126/500\n","6/6 [==============================] - 0s 12ms/step - loss: 4.3644e-04 - accuracy: 1.0000 - val_loss: 2.6815 - val_accuracy: 0.4762\n","Epoch 127/500\n","6/6 [==============================] - 0s 12ms/step - loss: 4.1632e-04 - accuracy: 1.0000 - val_loss: 2.6754 - val_accuracy: 0.5238\n","Epoch 128/500\n","6/6 [==============================] - 0s 13ms/step - loss: 3.9806e-04 - accuracy: 1.0000 - val_loss: 2.6865 - val_accuracy: 0.5238\n","Epoch 129/500\n","6/6 [==============================] - 0s 13ms/step - loss: 3.8786e-04 - accuracy: 1.0000 - val_loss: 2.7234 - val_accuracy: 0.5238\n","Epoch 130/500\n","6/6 [==============================] - 0s 12ms/step - loss: 3.7629e-04 - accuracy: 1.0000 - val_loss: 2.7478 - val_accuracy: 0.4762\n","Epoch 131/500\n","6/6 [==============================] - 0s 13ms/step - loss: 3.6210e-04 - accuracy: 1.0000 - val_loss: 2.7339 - val_accuracy: 0.5238\n","Epoch 132/500\n","6/6 [==============================] - 0s 13ms/step - loss: 3.5064e-04 - accuracy: 1.0000 - val_loss: 2.7485 - val_accuracy: 0.5238\n","Epoch 133/500\n","6/6 [==============================] - 0s 12ms/step - loss: 3.3931e-04 - accuracy: 1.0000 - val_loss: 2.7701 - val_accuracy: 0.5238\n","Epoch 134/500\n","6/6 [==============================] - 0s 14ms/step - loss: 3.3083e-04 - accuracy: 1.0000 - val_loss: 2.7810 - val_accuracy: 0.5238\n","Epoch 135/500\n","6/6 [==============================] - 0s 12ms/step - loss: 3.1993e-04 - accuracy: 1.0000 - val_loss: 2.7965 - val_accuracy: 0.5238\n","Epoch 136/500\n","6/6 [==============================] - 0s 14ms/step - loss: 3.1446e-04 - accuracy: 1.0000 - val_loss: 2.8239 - val_accuracy: 0.4762\n","Epoch 137/500\n","6/6 [==============================] - 0s 12ms/step - loss: 3.0767e-04 - accuracy: 1.0000 - val_loss: 2.8168 - val_accuracy: 0.5238\n","Epoch 138/500\n","6/6 [==============================] - 0s 12ms/step - loss: 2.9732e-04 - accuracy: 1.0000 - val_loss: 2.8242 - val_accuracy: 0.5238\n","Epoch 139/500\n","6/6 [==============================] - 0s 11ms/step - loss: 2.8929e-04 - accuracy: 1.0000 - val_loss: 2.8404 - val_accuracy: 0.5238\n","Epoch 140/500\n","6/6 [==============================] - 0s 12ms/step - loss: 2.8115e-04 - accuracy: 1.0000 - val_loss: 2.8674 - val_accuracy: 0.5238\n","Epoch 141/500\n","6/6 [==============================] - 0s 12ms/step - loss: 2.7755e-04 - accuracy: 1.0000 - val_loss: 2.8819 - val_accuracy: 0.4762\n","Epoch 142/500\n","6/6 [==============================] - 0s 12ms/step - loss: 2.6942e-04 - accuracy: 1.0000 - val_loss: 2.8832 - val_accuracy: 0.5238\n","Epoch 143/500\n","6/6 [==============================] - 0s 14ms/step - loss: 2.6299e-04 - accuracy: 1.0000 - val_loss: 2.8886 - val_accuracy: 0.5238\n","Epoch 144/500\n","6/6 [==============================] - 0s 14ms/step - loss: 2.5663e-04 - accuracy: 1.0000 - val_loss: 2.8886 - val_accuracy: 0.5238\n","Epoch 145/500\n","6/6 [==============================] - 0s 17ms/step - loss: 2.5228e-04 - accuracy: 1.0000 - val_loss: 2.8914 - val_accuracy: 0.5238\n","Epoch 146/500\n","6/6 [==============================] - 0s 14ms/step - loss: 2.4675e-04 - accuracy: 1.0000 - val_loss: 2.9070 - val_accuracy: 0.5238\n","Epoch 147/500\n","6/6 [==============================] - 0s 16ms/step - loss: 2.4123e-04 - accuracy: 1.0000 - val_loss: 2.9224 - val_accuracy: 0.5238\n","Epoch 148/500\n","6/6 [==============================] - 0s 14ms/step - loss: 2.3549e-04 - accuracy: 1.0000 - val_loss: 2.9343 - val_accuracy: 0.5238\n","Epoch 149/500\n","6/6 [==============================] - 0s 13ms/step - loss: 2.3095e-04 - accuracy: 1.0000 - val_loss: 2.9439 - val_accuracy: 0.5238\n","Epoch 150/500\n","6/6 [==============================] - 0s 15ms/step - loss: 2.2721e-04 - accuracy: 1.0000 - val_loss: 2.9529 - val_accuracy: 0.5238\n","Epoch 151/500\n","6/6 [==============================] - 0s 14ms/step - loss: 2.2236e-04 - accuracy: 1.0000 - val_loss: 2.9635 - val_accuracy: 0.5238\n","Epoch 152/500\n","6/6 [==============================] - 0s 14ms/step - loss: 2.1937e-04 - accuracy: 1.0000 - val_loss: 2.9558 - val_accuracy: 0.5238\n","Epoch 153/500\n","6/6 [==============================] - 0s 14ms/step - loss: 2.1470e-04 - accuracy: 1.0000 - val_loss: 2.9659 - val_accuracy: 0.5238\n","Epoch 154/500\n","6/6 [==============================] - 0s 14ms/step - loss: 2.0999e-04 - accuracy: 1.0000 - val_loss: 2.9792 - val_accuracy: 0.5238\n","Epoch 155/500\n","6/6 [==============================] - 0s 14ms/step - loss: 2.0596e-04 - accuracy: 1.0000 - val_loss: 2.9981 - val_accuracy: 0.5238\n","Epoch 156/500\n","6/6 [==============================] - 0s 15ms/step - loss: 2.0288e-04 - accuracy: 1.0000 - val_loss: 3.0057 - val_accuracy: 0.5238\n","Epoch 157/500\n","6/6 [==============================] - 0s 14ms/step - loss: 1.9832e-04 - accuracy: 1.0000 - val_loss: 3.0130 - val_accuracy: 0.5238\n","Epoch 158/500\n","6/6 [==============================] - 0s 18ms/step - loss: 1.9536e-04 - accuracy: 1.0000 - val_loss: 3.0177 - val_accuracy: 0.5238\n","Epoch 159/500\n","6/6 [==============================] - 0s 13ms/step - loss: 1.9148e-04 - accuracy: 1.0000 - val_loss: 3.0285 - val_accuracy: 0.5238\n","Epoch 160/500\n","6/6 [==============================] - 0s 13ms/step - loss: 1.8801e-04 - accuracy: 1.0000 - val_loss: 3.0352 - val_accuracy: 0.5238\n","Epoch 161/500\n","6/6 [==============================] - 0s 14ms/step - loss: 1.8553e-04 - accuracy: 1.0000 - val_loss: 3.0393 - val_accuracy: 0.5238\n","Epoch 162/500\n","6/6 [==============================] - 0s 17ms/step - loss: 1.8200e-04 - accuracy: 1.0000 - val_loss: 3.0493 - val_accuracy: 0.5238\n","Epoch 163/500\n","6/6 [==============================] - 0s 14ms/step - loss: 1.7957e-04 - accuracy: 1.0000 - val_loss: 3.0642 - val_accuracy: 0.5238\n","Epoch 164/500\n","6/6 [==============================] - 0s 17ms/step - loss: 1.7570e-04 - accuracy: 1.0000 - val_loss: 3.0704 - val_accuracy: 0.5238\n","Epoch 165/500\n","6/6 [==============================] - 0s 13ms/step - loss: 1.7400e-04 - accuracy: 1.0000 - val_loss: 3.0697 - val_accuracy: 0.5238\n","Epoch 166/500\n","6/6 [==============================] - 0s 13ms/step - loss: 1.7021e-04 - accuracy: 1.0000 - val_loss: 3.0813 - val_accuracy: 0.5238\n","Epoch 167/500\n","6/6 [==============================] - 0s 12ms/step - loss: 1.6763e-04 - accuracy: 1.0000 - val_loss: 3.0878 - val_accuracy: 0.5238\n","Epoch 168/500\n","6/6 [==============================] - 0s 12ms/step - loss: 1.6579e-04 - accuracy: 1.0000 - val_loss: 3.0903 - val_accuracy: 0.5238\n","Epoch 169/500\n","6/6 [==============================] - 0s 12ms/step - loss: 1.6312e-04 - accuracy: 1.0000 - val_loss: 3.1098 - val_accuracy: 0.5238\n","Epoch 170/500\n","6/6 [==============================] - 0s 13ms/step - loss: 1.6009e-04 - accuracy: 1.0000 - val_loss: 3.1161 - val_accuracy: 0.5238\n","Epoch 171/500\n","6/6 [==============================] - 0s 12ms/step - loss: 1.5781e-04 - accuracy: 1.0000 - val_loss: 3.1268 - val_accuracy: 0.5238\n","Epoch 172/500\n","6/6 [==============================] - 0s 12ms/step - loss: 1.5466e-04 - accuracy: 1.0000 - val_loss: 3.1285 - val_accuracy: 0.5238\n","Epoch 173/500\n","6/6 [==============================] - 0s 12ms/step - loss: 1.5432e-04 - accuracy: 1.0000 - val_loss: 3.1213 - val_accuracy: 0.5238\n","Epoch 174/500\n","6/6 [==============================] - 0s 12ms/step - loss: 1.5066e-04 - accuracy: 1.0000 - val_loss: 3.1332 - val_accuracy: 0.5238\n","Epoch 175/500\n","6/6 [==============================] - 0s 15ms/step - loss: 1.4820e-04 - accuracy: 1.0000 - val_loss: 3.1441 - val_accuracy: 0.5238\n","Epoch 176/500\n","6/6 [==============================] - 0s 12ms/step - loss: 1.4621e-04 - accuracy: 1.0000 - val_loss: 3.1615 - val_accuracy: 0.5238\n","Epoch 177/500\n","6/6 [==============================] - 0s 12ms/step - loss: 1.4425e-04 - accuracy: 1.0000 - val_loss: 3.1691 - val_accuracy: 0.5238\n","Epoch 178/500\n","6/6 [==============================] - 0s 14ms/step - loss: 1.4244e-04 - accuracy: 1.0000 - val_loss: 3.1718 - val_accuracy: 0.5238\n","Epoch 179/500\n","6/6 [==============================] - 0s 12ms/step - loss: 1.3977e-04 - accuracy: 1.0000 - val_loss: 3.1756 - val_accuracy: 0.5238\n","Epoch 180/500\n","6/6 [==============================] - 0s 13ms/step - loss: 1.3804e-04 - accuracy: 1.0000 - val_loss: 3.1827 - val_accuracy: 0.5238\n","Epoch 181/500\n","6/6 [==============================] - 0s 12ms/step - loss: 1.3691e-04 - accuracy: 1.0000 - val_loss: 3.1789 - val_accuracy: 0.5238\n","Epoch 182/500\n","6/6 [==============================] - 0s 12ms/step - loss: 1.3456e-04 - accuracy: 1.0000 - val_loss: 3.1860 - val_accuracy: 0.5238\n","Epoch 183/500\n","6/6 [==============================] - 0s 13ms/step - loss: 1.3251e-04 - accuracy: 1.0000 - val_loss: 3.1990 - val_accuracy: 0.5238\n","Epoch 184/500\n","6/6 [==============================] - 0s 12ms/step - loss: 1.3097e-04 - accuracy: 1.0000 - val_loss: 3.2105 - val_accuracy: 0.5238\n","Epoch 185/500\n","6/6 [==============================] - 0s 12ms/step - loss: 1.2925e-04 - accuracy: 1.0000 - val_loss: 3.2161 - val_accuracy: 0.5238\n","Epoch 186/500\n","6/6 [==============================] - 0s 12ms/step - loss: 1.2781e-04 - accuracy: 1.0000 - val_loss: 3.2167 - val_accuracy: 0.5238\n","Epoch 187/500\n","6/6 [==============================] - 0s 13ms/step - loss: 1.2631e-04 - accuracy: 1.0000 - val_loss: 3.2182 - val_accuracy: 0.5238\n","Epoch 188/500\n","6/6 [==============================] - 0s 11ms/step - loss: 1.2557e-04 - accuracy: 1.0000 - val_loss: 3.2396 - val_accuracy: 0.5238\n","Epoch 189/500\n","6/6 [==============================] - 0s 13ms/step - loss: 1.2293e-04 - accuracy: 1.0000 - val_loss: 3.2403 - val_accuracy: 0.5238\n","Epoch 190/500\n","6/6 [==============================] - 0s 13ms/step - loss: 1.2148e-04 - accuracy: 1.0000 - val_loss: 3.2379 - val_accuracy: 0.5238\n","Epoch 191/500\n","6/6 [==============================] - 0s 15ms/step - loss: 1.1978e-04 - accuracy: 1.0000 - val_loss: 3.2515 - val_accuracy: 0.5238\n","Epoch 192/500\n","6/6 [==============================] - 0s 14ms/step - loss: 1.1886e-04 - accuracy: 1.0000 - val_loss: 3.2488 - val_accuracy: 0.5238\n","Epoch 193/500\n","6/6 [==============================] - 0s 17ms/step - loss: 1.1660e-04 - accuracy: 1.0000 - val_loss: 3.2554 - val_accuracy: 0.5238\n","Epoch 194/500\n","6/6 [==============================] - 0s 13ms/step - loss: 1.1504e-04 - accuracy: 1.0000 - val_loss: 3.2620 - val_accuracy: 0.5238\n","Epoch 195/500\n","6/6 [==============================] - 0s 17ms/step - loss: 1.1401e-04 - accuracy: 1.0000 - val_loss: 3.2647 - val_accuracy: 0.5238\n","Epoch 196/500\n","6/6 [==============================] - 0s 14ms/step - loss: 1.1253e-04 - accuracy: 1.0000 - val_loss: 3.2715 - val_accuracy: 0.5238\n","Epoch 197/500\n","6/6 [==============================] - 0s 13ms/step - loss: 1.1142e-04 - accuracy: 1.0000 - val_loss: 3.2696 - val_accuracy: 0.5238\n","Epoch 198/500\n","6/6 [==============================] - 0s 14ms/step - loss: 1.1054e-04 - accuracy: 1.0000 - val_loss: 3.2741 - val_accuracy: 0.5238\n","Epoch 199/500\n","6/6 [==============================] - 0s 17ms/step - loss: 1.0840e-04 - accuracy: 1.0000 - val_loss: 3.2831 - val_accuracy: 0.5238\n","Epoch 200/500\n","6/6 [==============================] - 0s 14ms/step - loss: 1.0887e-04 - accuracy: 1.0000 - val_loss: 3.3010 - val_accuracy: 0.5238\n","Epoch 201/500\n","6/6 [==============================] - 0s 17ms/step - loss: 1.0636e-04 - accuracy: 1.0000 - val_loss: 3.2963 - val_accuracy: 0.5238\n","Epoch 202/500\n","6/6 [==============================] - 0s 13ms/step - loss: 1.0475e-04 - accuracy: 1.0000 - val_loss: 3.2935 - val_accuracy: 0.5238\n","Epoch 203/500\n","6/6 [==============================] - 0s 15ms/step - loss: 1.0379e-04 - accuracy: 1.0000 - val_loss: 3.2938 - val_accuracy: 0.5238\n","Epoch 204/500\n","6/6 [==============================] - 0s 13ms/step - loss: 1.0275e-04 - accuracy: 1.0000 - val_loss: 3.3004 - val_accuracy: 0.5238\n","Epoch 205/500\n","6/6 [==============================] - 0s 12ms/step - loss: 1.0212e-04 - accuracy: 1.0000 - val_loss: 3.3103 - val_accuracy: 0.5238\n","Epoch 206/500\n","6/6 [==============================] - 0s 14ms/step - loss: 1.0123e-04 - accuracy: 1.0000 - val_loss: 3.3013 - val_accuracy: 0.5238\n","Epoch 207/500\n","6/6 [==============================] - 0s 11ms/step - loss: 9.9907e-05 - accuracy: 1.0000 - val_loss: 3.3062 - val_accuracy: 0.5238\n","Epoch 208/500\n","6/6 [==============================] - 0s 13ms/step - loss: 9.8240e-05 - accuracy: 1.0000 - val_loss: 3.3184 - val_accuracy: 0.5238\n","Epoch 209/500\n","6/6 [==============================] - 0s 12ms/step - loss: 9.7478e-05 - accuracy: 1.0000 - val_loss: 3.3300 - val_accuracy: 0.5238\n","Epoch 210/500\n","6/6 [==============================] - 0s 12ms/step - loss: 9.7197e-05 - accuracy: 1.0000 - val_loss: 3.3411 - val_accuracy: 0.5238\n","Epoch 211/500\n","6/6 [==============================] - 0s 12ms/step - loss: 9.5560e-05 - accuracy: 1.0000 - val_loss: 3.3308 - val_accuracy: 0.5238\n","Epoch 212/500\n","6/6 [==============================] - 0s 16ms/step - loss: 9.4131e-05 - accuracy: 1.0000 - val_loss: 3.3291 - val_accuracy: 0.5238\n","Epoch 213/500\n","6/6 [==============================] - 0s 13ms/step - loss: 9.3648e-05 - accuracy: 1.0000 - val_loss: 3.3344 - val_accuracy: 0.5238\n","Epoch 214/500\n","6/6 [==============================] - 0s 13ms/step - loss: 9.2403e-05 - accuracy: 1.0000 - val_loss: 3.3370 - val_accuracy: 0.5238\n","Epoch 215/500\n","6/6 [==============================] - 0s 13ms/step - loss: 9.1957e-05 - accuracy: 1.0000 - val_loss: 3.3383 - val_accuracy: 0.5238\n","Epoch 216/500\n","6/6 [==============================] - 0s 13ms/step - loss: 9.0479e-05 - accuracy: 1.0000 - val_loss: 3.3476 - val_accuracy: 0.5238\n","Epoch 217/500\n","6/6 [==============================] - 0s 12ms/step - loss: 8.9854e-05 - accuracy: 1.0000 - val_loss: 3.3511 - val_accuracy: 0.5238\n","Epoch 218/500\n","6/6 [==============================] - 0s 13ms/step - loss: 8.9286e-05 - accuracy: 1.0000 - val_loss: 3.3654 - val_accuracy: 0.5238\n","Epoch 219/500\n","6/6 [==============================] - 0s 15ms/step - loss: 8.8255e-05 - accuracy: 1.0000 - val_loss: 3.3626 - val_accuracy: 0.5238\n","Epoch 220/500\n","6/6 [==============================] - 0s 14ms/step - loss: 8.7257e-05 - accuracy: 1.0000 - val_loss: 3.3670 - val_accuracy: 0.5238\n","Epoch 221/500\n","6/6 [==============================] - 0s 12ms/step - loss: 8.6413e-05 - accuracy: 1.0000 - val_loss: 3.3627 - val_accuracy: 0.5238\n","Epoch 222/500\n","6/6 [==============================] - 0s 13ms/step - loss: 8.5555e-05 - accuracy: 1.0000 - val_loss: 3.3617 - val_accuracy: 0.5238\n","Epoch 223/500\n","6/6 [==============================] - 0s 12ms/step - loss: 8.5161e-05 - accuracy: 1.0000 - val_loss: 3.3619 - val_accuracy: 0.5238\n","Epoch 224/500\n","6/6 [==============================] - 0s 12ms/step - loss: 8.4131e-05 - accuracy: 1.0000 - val_loss: 3.3713 - val_accuracy: 0.5238\n","Epoch 225/500\n","6/6 [==============================] - 0s 13ms/step - loss: 8.3602e-05 - accuracy: 1.0000 - val_loss: 3.3865 - val_accuracy: 0.5238\n","Epoch 226/500\n","6/6 [==============================] - 0s 12ms/step - loss: 8.2547e-05 - accuracy: 1.0000 - val_loss: 3.3906 - val_accuracy: 0.5238\n","Epoch 227/500\n","6/6 [==============================] - 0s 13ms/step - loss: 8.1703e-05 - accuracy: 1.0000 - val_loss: 3.3899 - val_accuracy: 0.5238\n","Epoch 228/500\n","6/6 [==============================] - 0s 12ms/step - loss: 8.0852e-05 - accuracy: 1.0000 - val_loss: 3.3893 - val_accuracy: 0.5238\n","Epoch 229/500\n","6/6 [==============================] - 0s 13ms/step - loss: 8.0345e-05 - accuracy: 1.0000 - val_loss: 3.3920 - val_accuracy: 0.5238\n","Epoch 230/500\n","6/6 [==============================] - 0s 13ms/step - loss: 7.9696e-05 - accuracy: 1.0000 - val_loss: 3.3881 - val_accuracy: 0.5238\n","Epoch 231/500\n","6/6 [==============================] - 0s 13ms/step - loss: 7.9060e-05 - accuracy: 1.0000 - val_loss: 3.3923 - val_accuracy: 0.5238\n","Epoch 232/500\n","6/6 [==============================] - 0s 13ms/step - loss: 7.9095e-05 - accuracy: 1.0000 - val_loss: 3.4085 - val_accuracy: 0.5238\n","Epoch 233/500\n","6/6 [==============================] - 0s 13ms/step - loss: 7.7451e-05 - accuracy: 1.0000 - val_loss: 3.4097 - val_accuracy: 0.5238\n","Epoch 234/500\n","6/6 [==============================] - 0s 14ms/step - loss: 7.6549e-05 - accuracy: 1.0000 - val_loss: 3.4091 - val_accuracy: 0.5238\n","Epoch 235/500\n","6/6 [==============================] - 0s 13ms/step - loss: 7.6062e-05 - accuracy: 1.0000 - val_loss: 3.4062 - val_accuracy: 0.5238\n","Epoch 236/500\n","6/6 [==============================] - 0s 12ms/step - loss: 7.5202e-05 - accuracy: 1.0000 - val_loss: 3.4103 - val_accuracy: 0.5238\n","Epoch 237/500\n","6/6 [==============================] - 0s 15ms/step - loss: 7.4801e-05 - accuracy: 1.0000 - val_loss: 3.4186 - val_accuracy: 0.5238\n","Epoch 238/500\n","6/6 [==============================] - 0s 12ms/step - loss: 7.3996e-05 - accuracy: 1.0000 - val_loss: 3.4186 - val_accuracy: 0.5238\n","Epoch 239/500\n","6/6 [==============================] - 0s 13ms/step - loss: 7.3403e-05 - accuracy: 1.0000 - val_loss: 3.4202 - val_accuracy: 0.5238\n","Epoch 240/500\n","6/6 [==============================] - 0s 12ms/step - loss: 7.2732e-05 - accuracy: 1.0000 - val_loss: 3.4229 - val_accuracy: 0.5238\n","Epoch 241/500\n","6/6 [==============================] - 0s 13ms/step - loss: 7.2061e-05 - accuracy: 1.0000 - val_loss: 3.4298 - val_accuracy: 0.5238\n","Epoch 242/500\n","6/6 [==============================] - 0s 11ms/step - loss: 7.1569e-05 - accuracy: 1.0000 - val_loss: 3.4393 - val_accuracy: 0.5238\n","Epoch 243/500\n","6/6 [==============================] - 0s 13ms/step - loss: 7.1100e-05 - accuracy: 1.0000 - val_loss: 3.4422 - val_accuracy: 0.5238\n","Epoch 244/500\n","6/6 [==============================] - 0s 12ms/step - loss: 6.9987e-05 - accuracy: 1.0000 - val_loss: 3.4422 - val_accuracy: 0.5238\n","Epoch 245/500\n","6/6 [==============================] - 0s 15ms/step - loss: 6.9683e-05 - accuracy: 1.0000 - val_loss: 3.4376 - val_accuracy: 0.5238\n","Epoch 246/500\n","6/6 [==============================] - 0s 12ms/step - loss: 6.8865e-05 - accuracy: 1.0000 - val_loss: 3.4383 - val_accuracy: 0.5238\n","Epoch 247/500\n","6/6 [==============================] - 0s 13ms/step - loss: 6.8252e-05 - accuracy: 1.0000 - val_loss: 3.4433 - val_accuracy: 0.5238\n","Epoch 248/500\n","6/6 [==============================] - 0s 12ms/step - loss: 6.7789e-05 - accuracy: 1.0000 - val_loss: 3.4461 - val_accuracy: 0.5238\n","Epoch 249/500\n","6/6 [==============================] - 0s 13ms/step - loss: 6.7101e-05 - accuracy: 1.0000 - val_loss: 3.4561 - val_accuracy: 0.5238\n","Epoch 250/500\n","6/6 [==============================] - 0s 12ms/step - loss: 6.6724e-05 - accuracy: 1.0000 - val_loss: 3.4647 - val_accuracy: 0.5238\n","Epoch 251/500\n","6/6 [==============================] - 0s 12ms/step - loss: 6.6446e-05 - accuracy: 1.0000 - val_loss: 3.4602 - val_accuracy: 0.5238\n","Epoch 252/500\n","6/6 [==============================] - 0s 13ms/step - loss: 6.5815e-05 - accuracy: 1.0000 - val_loss: 3.4595 - val_accuracy: 0.5238\n","Epoch 253/500\n","6/6 [==============================] - 0s 13ms/step - loss: 6.4834e-05 - accuracy: 1.0000 - val_loss: 3.4685 - val_accuracy: 0.5238\n","Epoch 254/500\n","6/6 [==============================] - 0s 12ms/step - loss: 6.4331e-05 - accuracy: 1.0000 - val_loss: 3.4731 - val_accuracy: 0.5238\n","Epoch 255/500\n","6/6 [==============================] - 0s 12ms/step - loss: 6.3926e-05 - accuracy: 1.0000 - val_loss: 3.4725 - val_accuracy: 0.5238\n","Epoch 256/500\n","6/6 [==============================] - 0s 13ms/step - loss: 6.3284e-05 - accuracy: 1.0000 - val_loss: 3.4803 - val_accuracy: 0.5238\n","Epoch 257/500\n","6/6 [==============================] - 0s 13ms/step - loss: 6.2855e-05 - accuracy: 1.0000 - val_loss: 3.4851 - val_accuracy: 0.5238\n","Epoch 258/500\n","6/6 [==============================] - 0s 13ms/step - loss: 6.2188e-05 - accuracy: 1.0000 - val_loss: 3.4812 - val_accuracy: 0.5238\n","Epoch 259/500\n","6/6 [==============================] - 0s 12ms/step - loss: 6.1838e-05 - accuracy: 1.0000 - val_loss: 3.4781 - val_accuracy: 0.5238\n","Epoch 260/500\n","6/6 [==============================] - 0s 13ms/step - loss: 6.1359e-05 - accuracy: 1.0000 - val_loss: 3.4847 - val_accuracy: 0.5238\n","Epoch 261/500\n","6/6 [==============================] - 0s 12ms/step - loss: 6.0705e-05 - accuracy: 1.0000 - val_loss: 3.4886 - val_accuracy: 0.5238\n","Epoch 262/500\n","6/6 [==============================] - 0s 13ms/step - loss: 6.0365e-05 - accuracy: 1.0000 - val_loss: 3.4959 - val_accuracy: 0.5238\n","Epoch 263/500\n","6/6 [==============================] - 0s 12ms/step - loss: 5.9748e-05 - accuracy: 1.0000 - val_loss: 3.4937 - val_accuracy: 0.5238\n","Epoch 264/500\n","6/6 [==============================] - 0s 13ms/step - loss: 5.9454e-05 - accuracy: 1.0000 - val_loss: 3.5005 - val_accuracy: 0.5238\n","Epoch 265/500\n","6/6 [==============================] - 0s 13ms/step - loss: 5.8955e-05 - accuracy: 1.0000 - val_loss: 3.5036 - val_accuracy: 0.5238\n","Epoch 266/500\n","6/6 [==============================] - 0s 13ms/step - loss: 5.8470e-05 - accuracy: 1.0000 - val_loss: 3.5080 - val_accuracy: 0.5238\n","Epoch 267/500\n","6/6 [==============================] - 0s 12ms/step - loss: 5.7787e-05 - accuracy: 1.0000 - val_loss: 3.5056 - val_accuracy: 0.5238\n","Epoch 268/500\n","6/6 [==============================] - 0s 17ms/step - loss: 5.7310e-05 - accuracy: 1.0000 - val_loss: 3.5080 - val_accuracy: 0.5238\n","Epoch 269/500\n","6/6 [==============================] - 0s 12ms/step - loss: 5.6912e-05 - accuracy: 1.0000 - val_loss: 3.5108 - val_accuracy: 0.5238\n","Epoch 270/500\n","6/6 [==============================] - 0s 14ms/step - loss: 5.6663e-05 - accuracy: 1.0000 - val_loss: 3.5178 - val_accuracy: 0.5238\n","Epoch 271/500\n","6/6 [==============================] - 0s 13ms/step - loss: 5.6010e-05 - accuracy: 1.0000 - val_loss: 3.5193 - val_accuracy: 0.5238\n","Epoch 272/500\n","6/6 [==============================] - 0s 13ms/step - loss: 5.5631e-05 - accuracy: 1.0000 - val_loss: 3.5208 - val_accuracy: 0.5238\n","Epoch 273/500\n","6/6 [==============================] - 0s 12ms/step - loss: 5.5238e-05 - accuracy: 1.0000 - val_loss: 3.5272 - val_accuracy: 0.5238\n","Epoch 274/500\n","6/6 [==============================] - 0s 13ms/step - loss: 5.4830e-05 - accuracy: 1.0000 - val_loss: 3.5304 - val_accuracy: 0.5238\n","Epoch 275/500\n","6/6 [==============================] - 0s 13ms/step - loss: 5.4417e-05 - accuracy: 1.0000 - val_loss: 3.5302 - val_accuracy: 0.5238\n","Epoch 276/500\n","6/6 [==============================] - 0s 13ms/step - loss: 5.3846e-05 - accuracy: 1.0000 - val_loss: 3.5320 - val_accuracy: 0.5238\n","Epoch 277/500\n","6/6 [==============================] - 0s 13ms/step - loss: 5.3541e-05 - accuracy: 1.0000 - val_loss: 3.5347 - val_accuracy: 0.5238\n","Epoch 278/500\n","6/6 [==============================] - 0s 12ms/step - loss: 5.3088e-05 - accuracy: 1.0000 - val_loss: 3.5387 - val_accuracy: 0.5238\n","Epoch 279/500\n","6/6 [==============================] - 0s 13ms/step - loss: 5.2645e-05 - accuracy: 1.0000 - val_loss: 3.5464 - val_accuracy: 0.5238\n","Epoch 280/500\n","6/6 [==============================] - 0s 12ms/step - loss: 5.2359e-05 - accuracy: 1.0000 - val_loss: 3.5480 - val_accuracy: 0.5238\n","Epoch 281/500\n","6/6 [==============================] - 0s 12ms/step - loss: 5.1896e-05 - accuracy: 1.0000 - val_loss: 3.5542 - val_accuracy: 0.5238\n","Epoch 282/500\n","6/6 [==============================] - 0s 13ms/step - loss: 5.1515e-05 - accuracy: 1.0000 - val_loss: 3.5575 - val_accuracy: 0.5238\n","Epoch 283/500\n","6/6 [==============================] - 0s 14ms/step - loss: 5.1223e-05 - accuracy: 1.0000 - val_loss: 3.5644 - val_accuracy: 0.5238\n","Epoch 284/500\n","6/6 [==============================] - 0s 12ms/step - loss: 5.0809e-05 - accuracy: 1.0000 - val_loss: 3.5674 - val_accuracy: 0.5238\n","Epoch 285/500\n","6/6 [==============================] - 0s 12ms/step - loss: 5.0094e-05 - accuracy: 1.0000 - val_loss: 3.5648 - val_accuracy: 0.5238\n","Epoch 286/500\n","6/6 [==============================] - 0s 13ms/step - loss: 4.9773e-05 - accuracy: 1.0000 - val_loss: 3.5633 - val_accuracy: 0.5238\n","Epoch 287/500\n","6/6 [==============================] - 0s 13ms/step - loss: 4.9627e-05 - accuracy: 1.0000 - val_loss: 3.5607 - val_accuracy: 0.5238\n","Epoch 288/500\n","6/6 [==============================] - 0s 13ms/step - loss: 4.9469e-05 - accuracy: 1.0000 - val_loss: 3.5615 - val_accuracy: 0.5238\n","Epoch 289/500\n","6/6 [==============================] - 0s 12ms/step - loss: 4.8783e-05 - accuracy: 1.0000 - val_loss: 3.5716 - val_accuracy: 0.5238\n","Epoch 290/500\n","6/6 [==============================] - 0s 12ms/step - loss: 4.8364e-05 - accuracy: 1.0000 - val_loss: 3.5794 - val_accuracy: 0.5238\n","Epoch 291/500\n","6/6 [==============================] - 0s 14ms/step - loss: 4.8003e-05 - accuracy: 1.0000 - val_loss: 3.5837 - val_accuracy: 0.5238\n","Epoch 292/500\n","6/6 [==============================] - 0s 12ms/step - loss: 4.7742e-05 - accuracy: 1.0000 - val_loss: 3.5854 - val_accuracy: 0.5238\n","Epoch 293/500\n","6/6 [==============================] - 0s 14ms/step - loss: 4.7451e-05 - accuracy: 1.0000 - val_loss: 3.5939 - val_accuracy: 0.5238\n","Epoch 294/500\n","6/6 [==============================] - 0s 13ms/step - loss: 4.7183e-05 - accuracy: 1.0000 - val_loss: 3.5972 - val_accuracy: 0.5238\n","Epoch 295/500\n","6/6 [==============================] - 0s 26ms/step - loss: 4.7054e-05 - accuracy: 1.0000 - val_loss: 3.5897 - val_accuracy: 0.5238\n","Epoch 296/500\n","6/6 [==============================] - 0s 37ms/step - loss: 4.6463e-05 - accuracy: 1.0000 - val_loss: 3.5889 - val_accuracy: 0.5238\n","Epoch 297/500\n","6/6 [==============================] - 0s 36ms/step - loss: 4.6040e-05 - accuracy: 1.0000 - val_loss: 3.5980 - val_accuracy: 0.5238\n","Epoch 298/500\n","6/6 [==============================] - 0s 26ms/step - loss: 4.5575e-05 - accuracy: 1.0000 - val_loss: 3.6024 - val_accuracy: 0.5238\n","Epoch 299/500\n","6/6 [==============================] - 0s 14ms/step - loss: 4.5350e-05 - accuracy: 1.0000 - val_loss: 3.6108 - val_accuracy: 0.5238\n","Epoch 300/500\n","6/6 [==============================] - 0s 13ms/step - loss: 4.4933e-05 - accuracy: 1.0000 - val_loss: 3.6124 - val_accuracy: 0.5238\n","Epoch 301/500\n","6/6 [==============================] - 0s 14ms/step - loss: 4.4682e-05 - accuracy: 1.0000 - val_loss: 3.6102 - val_accuracy: 0.5238\n","Epoch 302/500\n","6/6 [==============================] - 0s 19ms/step - loss: 4.4396e-05 - accuracy: 1.0000 - val_loss: 3.6127 - val_accuracy: 0.5238\n","Epoch 303/500\n","6/6 [==============================] - 0s 23ms/step - loss: 4.4134e-05 - accuracy: 1.0000 - val_loss: 3.6216 - val_accuracy: 0.5238\n","Epoch 304/500\n","6/6 [==============================] - 0s 24ms/step - loss: 4.3767e-05 - accuracy: 1.0000 - val_loss: 3.6186 - val_accuracy: 0.5238\n","Epoch 305/500\n","6/6 [==============================] - 0s 33ms/step - loss: 4.3546e-05 - accuracy: 1.0000 - val_loss: 3.6272 - val_accuracy: 0.5238\n","Epoch 306/500\n","6/6 [==============================] - 0s 33ms/step - loss: 4.3151e-05 - accuracy: 1.0000 - val_loss: 3.6303 - val_accuracy: 0.5238\n","Epoch 307/500\n","6/6 [==============================] - 0s 25ms/step - loss: 4.2992e-05 - accuracy: 1.0000 - val_loss: 3.6234 - val_accuracy: 0.5238\n","Epoch 308/500\n","6/6 [==============================] - 0s 13ms/step - loss: 4.2557e-05 - accuracy: 1.0000 - val_loss: 3.6248 - val_accuracy: 0.5238\n","Epoch 309/500\n","6/6 [==============================] - 0s 14ms/step - loss: 4.2203e-05 - accuracy: 1.0000 - val_loss: 3.6325 - val_accuracy: 0.5238\n","Epoch 310/500\n","6/6 [==============================] - 0s 14ms/step - loss: 4.1811e-05 - accuracy: 1.0000 - val_loss: 3.6377 - val_accuracy: 0.5238\n","Epoch 311/500\n","6/6 [==============================] - 0s 12ms/step - loss: 4.1514e-05 - accuracy: 1.0000 - val_loss: 3.6419 - val_accuracy: 0.5238\n","Epoch 312/500\n","6/6 [==============================] - 0s 16ms/step - loss: 4.1247e-05 - accuracy: 1.0000 - val_loss: 3.6450 - val_accuracy: 0.5238\n","Epoch 313/500\n","6/6 [==============================] - 0s 13ms/step - loss: 4.0948e-05 - accuracy: 1.0000 - val_loss: 3.6514 - val_accuracy: 0.5238\n","Epoch 314/500\n","6/6 [==============================] - 0s 18ms/step - loss: 4.0838e-05 - accuracy: 1.0000 - val_loss: 3.6581 - val_accuracy: 0.5238\n","Epoch 315/500\n","6/6 [==============================] - 0s 12ms/step - loss: 4.0412e-05 - accuracy: 1.0000 - val_loss: 3.6594 - val_accuracy: 0.5238\n","Epoch 316/500\n","6/6 [==============================] - 0s 13ms/step - loss: 3.9996e-05 - accuracy: 1.0000 - val_loss: 3.6553 - val_accuracy: 0.5238\n","Epoch 317/500\n","6/6 [==============================] - 0s 12ms/step - loss: 3.9748e-05 - accuracy: 1.0000 - val_loss: 3.6533 - val_accuracy: 0.5238\n","Epoch 318/500\n","6/6 [==============================] - 0s 13ms/step - loss: 3.9630e-05 - accuracy: 1.0000 - val_loss: 3.6534 - val_accuracy: 0.5238\n","Epoch 319/500\n","6/6 [==============================] - 0s 13ms/step - loss: 3.9373e-05 - accuracy: 1.0000 - val_loss: 3.6621 - val_accuracy: 0.5238\n","Epoch 320/500\n","6/6 [==============================] - 0s 12ms/step - loss: 3.9167e-05 - accuracy: 1.0000 - val_loss: 3.6615 - val_accuracy: 0.5238\n","Epoch 321/500\n","6/6 [==============================] - 0s 14ms/step - loss: 3.8698e-05 - accuracy: 1.0000 - val_loss: 3.6682 - val_accuracy: 0.5238\n","Epoch 322/500\n","6/6 [==============================] - 0s 14ms/step - loss: 3.8535e-05 - accuracy: 1.0000 - val_loss: 3.6758 - val_accuracy: 0.5238\n","Epoch 323/500\n","6/6 [==============================] - 0s 13ms/step - loss: 3.8243e-05 - accuracy: 1.0000 - val_loss: 3.6764 - val_accuracy: 0.5238\n","Epoch 324/500\n","6/6 [==============================] - 0s 14ms/step - loss: 3.7927e-05 - accuracy: 1.0000 - val_loss: 3.6789 - val_accuracy: 0.5238\n","Epoch 325/500\n","6/6 [==============================] - 0s 12ms/step - loss: 3.7633e-05 - accuracy: 1.0000 - val_loss: 3.6813 - val_accuracy: 0.5238\n","Epoch 326/500\n","6/6 [==============================] - 0s 13ms/step - loss: 3.7414e-05 - accuracy: 1.0000 - val_loss: 3.6860 - val_accuracy: 0.5238\n","Epoch 327/500\n","6/6 [==============================] - 0s 13ms/step - loss: 3.7243e-05 - accuracy: 1.0000 - val_loss: 3.6898 - val_accuracy: 0.5238\n","Epoch 328/500\n","6/6 [==============================] - 0s 13ms/step - loss: 3.7012e-05 - accuracy: 1.0000 - val_loss: 3.6853 - val_accuracy: 0.5238\n","Epoch 329/500\n","6/6 [==============================] - 0s 12ms/step - loss: 3.6734e-05 - accuracy: 1.0000 - val_loss: 3.6878 - val_accuracy: 0.5238\n","Epoch 330/500\n","6/6 [==============================] - 0s 12ms/step - loss: 3.6517e-05 - accuracy: 1.0000 - val_loss: 3.6894 - val_accuracy: 0.5238\n","Epoch 331/500\n","6/6 [==============================] - 0s 12ms/step - loss: 3.6336e-05 - accuracy: 1.0000 - val_loss: 3.6987 - val_accuracy: 0.5238\n","Epoch 332/500\n","6/6 [==============================] - 0s 12ms/step - loss: 3.6057e-05 - accuracy: 1.0000 - val_loss: 3.6981 - val_accuracy: 0.5238\n","Epoch 333/500\n","6/6 [==============================] - 0s 13ms/step - loss: 3.5760e-05 - accuracy: 1.0000 - val_loss: 3.7033 - val_accuracy: 0.5238\n","Epoch 334/500\n","6/6 [==============================] - 0s 16ms/step - loss: 3.5499e-05 - accuracy: 1.0000 - val_loss: 3.7049 - val_accuracy: 0.5238\n","Epoch 335/500\n","6/6 [==============================] - 0s 12ms/step - loss: 3.5255e-05 - accuracy: 1.0000 - val_loss: 3.7068 - val_accuracy: 0.5238\n","Epoch 336/500\n","6/6 [==============================] - 0s 13ms/step - loss: 3.4966e-05 - accuracy: 1.0000 - val_loss: 3.7118 - val_accuracy: 0.5238\n","Epoch 337/500\n","6/6 [==============================] - 0s 13ms/step - loss: 3.4969e-05 - accuracy: 1.0000 - val_loss: 3.7187 - val_accuracy: 0.5238\n","Epoch 338/500\n","6/6 [==============================] - 0s 13ms/step - loss: 3.4797e-05 - accuracy: 1.0000 - val_loss: 3.7131 - val_accuracy: 0.5238\n","Epoch 339/500\n","6/6 [==============================] - 0s 13ms/step - loss: 3.4359e-05 - accuracy: 1.0000 - val_loss: 3.7196 - val_accuracy: 0.5238\n","Epoch 340/500\n","6/6 [==============================] - 0s 13ms/step - loss: 3.4205e-05 - accuracy: 1.0000 - val_loss: 3.7191 - val_accuracy: 0.5238\n","Epoch 341/500\n","6/6 [==============================] - 0s 12ms/step - loss: 3.3844e-05 - accuracy: 1.0000 - val_loss: 3.7231 - val_accuracy: 0.5238\n","Epoch 342/500\n","6/6 [==============================] - 0s 13ms/step - loss: 3.3659e-05 - accuracy: 1.0000 - val_loss: 3.7274 - val_accuracy: 0.5238\n","Epoch 343/500\n","6/6 [==============================] - 0s 13ms/step - loss: 3.3708e-05 - accuracy: 1.0000 - val_loss: 3.7379 - val_accuracy: 0.5238\n","Epoch 344/500\n","6/6 [==============================] - 0s 14ms/step - loss: 3.3395e-05 - accuracy: 1.0000 - val_loss: 3.7328 - val_accuracy: 0.5238\n","Epoch 345/500\n","6/6 [==============================] - 0s 13ms/step - loss: 3.3196e-05 - accuracy: 1.0000 - val_loss: 3.7297 - val_accuracy: 0.5238\n","Epoch 346/500\n","6/6 [==============================] - 0s 14ms/step - loss: 3.2813e-05 - accuracy: 1.0000 - val_loss: 3.7345 - val_accuracy: 0.5238\n","Epoch 347/500\n","6/6 [==============================] - 0s 13ms/step - loss: 3.2623e-05 - accuracy: 1.0000 - val_loss: 3.7384 - val_accuracy: 0.5238\n","Epoch 348/500\n","6/6 [==============================] - 0s 13ms/step - loss: 3.2360e-05 - accuracy: 1.0000 - val_loss: 3.7440 - val_accuracy: 0.5238\n","Epoch 349/500\n","6/6 [==============================] - 0s 12ms/step - loss: 3.2289e-05 - accuracy: 1.0000 - val_loss: 3.7540 - val_accuracy: 0.5238\n","Epoch 350/500\n","6/6 [==============================] - 0s 13ms/step - loss: 3.2083e-05 - accuracy: 1.0000 - val_loss: 3.7595 - val_accuracy: 0.5238\n","Epoch 351/500\n","6/6 [==============================] - 0s 12ms/step - loss: 3.1984e-05 - accuracy: 1.0000 - val_loss: 3.7525 - val_accuracy: 0.5238\n","Epoch 352/500\n","6/6 [==============================] - 0s 12ms/step - loss: 3.1639e-05 - accuracy: 1.0000 - val_loss: 3.7575 - val_accuracy: 0.5238\n","Epoch 353/500\n","6/6 [==============================] - 0s 13ms/step - loss: 3.1375e-05 - accuracy: 1.0000 - val_loss: 3.7578 - val_accuracy: 0.5238\n","Epoch 354/500\n","6/6 [==============================] - 0s 13ms/step - loss: 3.1441e-05 - accuracy: 1.0000 - val_loss: 3.7510 - val_accuracy: 0.5238\n","Epoch 355/500\n","6/6 [==============================] - 0s 12ms/step - loss: 3.1111e-05 - accuracy: 1.0000 - val_loss: 3.7542 - val_accuracy: 0.5238\n","Epoch 356/500\n","6/6 [==============================] - 0s 13ms/step - loss: 3.0930e-05 - accuracy: 1.0000 - val_loss: 3.7641 - val_accuracy: 0.5238\n","Epoch 357/500\n","6/6 [==============================] - 0s 13ms/step - loss: 3.0667e-05 - accuracy: 1.0000 - val_loss: 3.7689 - val_accuracy: 0.5238\n","Epoch 358/500\n","6/6 [==============================] - 0s 18ms/step - loss: 3.0379e-05 - accuracy: 1.0000 - val_loss: 3.7692 - val_accuracy: 0.5238\n","Epoch 359/500\n","6/6 [==============================] - 0s 18ms/step - loss: 3.0242e-05 - accuracy: 1.0000 - val_loss: 3.7716 - val_accuracy: 0.5238\n","Epoch 360/500\n","6/6 [==============================] - 0s 13ms/step - loss: 3.0094e-05 - accuracy: 1.0000 - val_loss: 3.7774 - val_accuracy: 0.5238\n","Epoch 361/500\n","6/6 [==============================] - 0s 13ms/step - loss: 2.9825e-05 - accuracy: 1.0000 - val_loss: 3.7766 - val_accuracy: 0.5238\n","Epoch 362/500\n","6/6 [==============================] - 0s 12ms/step - loss: 2.9699e-05 - accuracy: 1.0000 - val_loss: 3.7754 - val_accuracy: 0.5238\n","Epoch 363/500\n","6/6 [==============================] - 0s 13ms/step - loss: 2.9522e-05 - accuracy: 1.0000 - val_loss: 3.7773 - val_accuracy: 0.5238\n","Epoch 364/500\n","6/6 [==============================] - 0s 12ms/step - loss: 2.9287e-05 - accuracy: 1.0000 - val_loss: 3.7830 - val_accuracy: 0.5238\n","Epoch 365/500\n","6/6 [==============================] - 0s 14ms/step - loss: 2.9075e-05 - accuracy: 1.0000 - val_loss: 3.7894 - val_accuracy: 0.5238\n","Epoch 366/500\n","6/6 [==============================] - 0s 13ms/step - loss: 2.9088e-05 - accuracy: 1.0000 - val_loss: 3.7989 - val_accuracy: 0.5238\n","Epoch 367/500\n","6/6 [==============================] - 0s 17ms/step - loss: 2.8815e-05 - accuracy: 1.0000 - val_loss: 3.8005 - val_accuracy: 0.5238\n","Epoch 368/500\n","6/6 [==============================] - 0s 13ms/step - loss: 2.8547e-05 - accuracy: 1.0000 - val_loss: 3.7975 - val_accuracy: 0.5238\n","Epoch 369/500\n","6/6 [==============================] - 0s 14ms/step - loss: 2.8526e-05 - accuracy: 1.0000 - val_loss: 3.7945 - val_accuracy: 0.5238\n","Epoch 370/500\n","6/6 [==============================] - 0s 13ms/step - loss: 2.8268e-05 - accuracy: 1.0000 - val_loss: 3.7955 - val_accuracy: 0.5238\n","Epoch 371/500\n","6/6 [==============================] - 0s 12ms/step - loss: 2.8146e-05 - accuracy: 1.0000 - val_loss: 3.8029 - val_accuracy: 0.5238\n","Epoch 372/500\n","6/6 [==============================] - 0s 12ms/step - loss: 2.7954e-05 - accuracy: 1.0000 - val_loss: 3.8022 - val_accuracy: 0.5238\n","Epoch 373/500\n","6/6 [==============================] - 0s 13ms/step - loss: 2.7750e-05 - accuracy: 1.0000 - val_loss: 3.8065 - val_accuracy: 0.5238\n","Epoch 374/500\n","6/6 [==============================] - 0s 13ms/step - loss: 2.7558e-05 - accuracy: 1.0000 - val_loss: 3.8096 - val_accuracy: 0.5238\n","Epoch 375/500\n","6/6 [==============================] - 0s 13ms/step - loss: 2.7397e-05 - accuracy: 1.0000 - val_loss: 3.8158 - val_accuracy: 0.5238\n","Epoch 376/500\n","6/6 [==============================] - 0s 12ms/step - loss: 2.7269e-05 - accuracy: 1.0000 - val_loss: 3.8194 - val_accuracy: 0.5238\n","Epoch 377/500\n","6/6 [==============================] - 0s 13ms/step - loss: 2.7221e-05 - accuracy: 1.0000 - val_loss: 3.8189 - val_accuracy: 0.5238\n","Epoch 378/500\n","6/6 [==============================] - 0s 14ms/step - loss: 2.7058e-05 - accuracy: 1.0000 - val_loss: 3.8185 - val_accuracy: 0.5238\n","Epoch 379/500\n","6/6 [==============================] - 0s 12ms/step - loss: 2.6729e-05 - accuracy: 1.0000 - val_loss: 3.8232 - val_accuracy: 0.5238\n","Epoch 380/500\n","6/6 [==============================] - 0s 16ms/step - loss: 2.6674e-05 - accuracy: 1.0000 - val_loss: 3.8311 - val_accuracy: 0.5238\n","Epoch 381/500\n","6/6 [==============================] - 0s 13ms/step - loss: 2.6506e-05 - accuracy: 1.0000 - val_loss: 3.8347 - val_accuracy: 0.5238\n","Epoch 382/500\n","6/6 [==============================] - 0s 16ms/step - loss: 2.6345e-05 - accuracy: 1.0000 - val_loss: 3.8324 - val_accuracy: 0.5238\n","Epoch 383/500\n","6/6 [==============================] - 0s 12ms/step - loss: 2.6380e-05 - accuracy: 1.0000 - val_loss: 3.8286 - val_accuracy: 0.5238\n","Epoch 384/500\n","6/6 [==============================] - 0s 14ms/step - loss: 2.6058e-05 - accuracy: 1.0000 - val_loss: 3.8305 - val_accuracy: 0.5238\n","Epoch 385/500\n","6/6 [==============================] - 0s 13ms/step - loss: 2.5909e-05 - accuracy: 1.0000 - val_loss: 3.8384 - val_accuracy: 0.5238\n","Epoch 386/500\n","6/6 [==============================] - 0s 14ms/step - loss: 2.5748e-05 - accuracy: 1.0000 - val_loss: 3.8438 - val_accuracy: 0.5238\n","Epoch 387/500\n","6/6 [==============================] - 0s 13ms/step - loss: 2.5601e-05 - accuracy: 1.0000 - val_loss: 3.8424 - val_accuracy: 0.5238\n","Epoch 388/500\n","6/6 [==============================] - 0s 13ms/step - loss: 2.5480e-05 - accuracy: 1.0000 - val_loss: 3.8427 - val_accuracy: 0.5238\n","Epoch 389/500\n","6/6 [==============================] - 0s 12ms/step - loss: 2.5263e-05 - accuracy: 1.0000 - val_loss: 3.8460 - val_accuracy: 0.5238\n","Epoch 390/500\n","6/6 [==============================] - 0s 13ms/step - loss: 2.5129e-05 - accuracy: 1.0000 - val_loss: 3.8530 - val_accuracy: 0.5238\n","Epoch 391/500\n","6/6 [==============================] - 0s 13ms/step - loss: 2.5043e-05 - accuracy: 1.0000 - val_loss: 3.8510 - val_accuracy: 0.5238\n","Epoch 392/500\n","6/6 [==============================] - 0s 14ms/step - loss: 2.4802e-05 - accuracy: 1.0000 - val_loss: 3.8542 - val_accuracy: 0.5238\n","Epoch 393/500\n","6/6 [==============================] - 0s 13ms/step - loss: 2.4649e-05 - accuracy: 1.0000 - val_loss: 3.8557 - val_accuracy: 0.5238\n","Epoch 394/500\n","6/6 [==============================] - 0s 16ms/step - loss: 2.4715e-05 - accuracy: 1.0000 - val_loss: 3.8539 - val_accuracy: 0.5238\n","Epoch 395/500\n","6/6 [==============================] - 0s 13ms/step - loss: 2.4511e-05 - accuracy: 1.0000 - val_loss: 3.8630 - val_accuracy: 0.5238\n","Epoch 396/500\n","6/6 [==============================] - 0s 13ms/step - loss: 2.4232e-05 - accuracy: 1.0000 - val_loss: 3.8653 - val_accuracy: 0.5238\n","Epoch 397/500\n","6/6 [==============================] - 0s 13ms/step - loss: 2.4115e-05 - accuracy: 1.0000 - val_loss: 3.8667 - val_accuracy: 0.5238\n","Epoch 398/500\n","6/6 [==============================] - 0s 14ms/step - loss: 2.3982e-05 - accuracy: 1.0000 - val_loss: 3.8668 - val_accuracy: 0.5238\n","Epoch 399/500\n","6/6 [==============================] - 0s 12ms/step - loss: 2.3817e-05 - accuracy: 1.0000 - val_loss: 3.8696 - val_accuracy: 0.5238\n","Epoch 400/500\n","6/6 [==============================] - 0s 14ms/step - loss: 2.3773e-05 - accuracy: 1.0000 - val_loss: 3.8709 - val_accuracy: 0.5238\n","Epoch 401/500\n","6/6 [==============================] - 0s 12ms/step - loss: 2.3517e-05 - accuracy: 1.0000 - val_loss: 3.8747 - val_accuracy: 0.5238\n","Epoch 402/500\n","6/6 [==============================] - 0s 13ms/step - loss: 2.3451e-05 - accuracy: 1.0000 - val_loss: 3.8809 - val_accuracy: 0.5238\n","Epoch 403/500\n","6/6 [==============================] - 0s 14ms/step - loss: 2.3348e-05 - accuracy: 1.0000 - val_loss: 3.8846 - val_accuracy: 0.5238\n","Epoch 404/500\n","6/6 [==============================] - 0s 14ms/step - loss: 2.3161e-05 - accuracy: 1.0000 - val_loss: 3.8852 - val_accuracy: 0.5238\n","Epoch 405/500\n","6/6 [==============================] - 0s 12ms/step - loss: 2.3080e-05 - accuracy: 1.0000 - val_loss: 3.8861 - val_accuracy: 0.5238\n","Epoch 406/500\n","6/6 [==============================] - 0s 14ms/step - loss: 2.2932e-05 - accuracy: 1.0000 - val_loss: 3.8896 - val_accuracy: 0.5238\n","Epoch 407/500\n","6/6 [==============================] - 0s 12ms/step - loss: 2.2750e-05 - accuracy: 1.0000 - val_loss: 3.8898 - val_accuracy: 0.5238\n","Epoch 408/500\n","6/6 [==============================] - 0s 13ms/step - loss: 2.2647e-05 - accuracy: 1.0000 - val_loss: 3.8911 - val_accuracy: 0.5238\n","Epoch 409/500\n","6/6 [==============================] - 0s 13ms/step - loss: 2.2535e-05 - accuracy: 1.0000 - val_loss: 3.8923 - val_accuracy: 0.5238\n","Epoch 410/500\n","6/6 [==============================] - 0s 12ms/step - loss: 2.2389e-05 - accuracy: 1.0000 - val_loss: 3.8921 - val_accuracy: 0.5238\n","Epoch 411/500\n","6/6 [==============================] - 0s 12ms/step - loss: 2.2474e-05 - accuracy: 1.0000 - val_loss: 3.8893 - val_accuracy: 0.5238\n","Epoch 412/500\n","6/6 [==============================] - 0s 13ms/step - loss: 2.2189e-05 - accuracy: 1.0000 - val_loss: 3.8937 - val_accuracy: 0.5238\n","Epoch 413/500\n","6/6 [==============================] - 0s 18ms/step - loss: 2.2030e-05 - accuracy: 1.0000 - val_loss: 3.9007 - val_accuracy: 0.5238\n","Epoch 414/500\n","6/6 [==============================] - 0s 18ms/step - loss: 2.1896e-05 - accuracy: 1.0000 - val_loss: 3.9057 - val_accuracy: 0.5238\n","Epoch 415/500\n","6/6 [==============================] - 0s 14ms/step - loss: 2.1811e-05 - accuracy: 1.0000 - val_loss: 3.9075 - val_accuracy: 0.5238\n","Epoch 416/500\n","6/6 [==============================] - 0s 16ms/step - loss: 2.1678e-05 - accuracy: 1.0000 - val_loss: 3.9093 - val_accuracy: 0.5238\n","Epoch 417/500\n","6/6 [==============================] - 0s 17ms/step - loss: 2.1636e-05 - accuracy: 1.0000 - val_loss: 3.9095 - val_accuracy: 0.5238\n","Epoch 418/500\n","6/6 [==============================] - 0s 17ms/step - loss: 2.1435e-05 - accuracy: 1.0000 - val_loss: 3.9123 - val_accuracy: 0.5238\n","Epoch 419/500\n","6/6 [==============================] - 0s 13ms/step - loss: 2.1392e-05 - accuracy: 1.0000 - val_loss: 3.9192 - val_accuracy: 0.5238\n","Epoch 420/500\n","6/6 [==============================] - 0s 17ms/step - loss: 2.1234e-05 - accuracy: 1.0000 - val_loss: 3.9226 - val_accuracy: 0.5238\n","Epoch 421/500\n","6/6 [==============================] - 0s 17ms/step - loss: 2.1130e-05 - accuracy: 1.0000 - val_loss: 3.9250 - val_accuracy: 0.5238\n","Epoch 422/500\n","6/6 [==============================] - 0s 17ms/step - loss: 2.1102e-05 - accuracy: 1.0000 - val_loss: 3.9190 - val_accuracy: 0.5238\n","Epoch 423/500\n","6/6 [==============================] - 0s 13ms/step - loss: 2.0858e-05 - accuracy: 1.0000 - val_loss: 3.9199 - val_accuracy: 0.5238\n","Epoch 424/500\n","6/6 [==============================] - 0s 13ms/step - loss: 2.0767e-05 - accuracy: 1.0000 - val_loss: 3.9220 - val_accuracy: 0.5238\n","Epoch 425/500\n","6/6 [==============================] - 0s 16ms/step - loss: 2.0618e-05 - accuracy: 1.0000 - val_loss: 3.9256 - val_accuracy: 0.5238\n","Epoch 426/500\n","6/6 [==============================] - 0s 13ms/step - loss: 2.0553e-05 - accuracy: 1.0000 - val_loss: 3.9308 - val_accuracy: 0.5238\n","Epoch 427/500\n","6/6 [==============================] - 0s 12ms/step - loss: 2.0393e-05 - accuracy: 1.0000 - val_loss: 3.9325 - val_accuracy: 0.5238\n","Epoch 428/500\n","6/6 [==============================] - 0s 16ms/step - loss: 2.0344e-05 - accuracy: 1.0000 - val_loss: 3.9332 - val_accuracy: 0.5238\n","Epoch 429/500\n","6/6 [==============================] - 0s 14ms/step - loss: 2.0176e-05 - accuracy: 1.0000 - val_loss: 3.9374 - val_accuracy: 0.5238\n","Epoch 430/500\n","6/6 [==============================] - 0s 13ms/step - loss: 2.0069e-05 - accuracy: 1.0000 - val_loss: 3.9383 - val_accuracy: 0.5238\n","Epoch 431/500\n","6/6 [==============================] - 0s 14ms/step - loss: 2.0006e-05 - accuracy: 1.0000 - val_loss: 3.9409 - val_accuracy: 0.5238\n","Epoch 432/500\n","6/6 [==============================] - 0s 13ms/step - loss: 1.9874e-05 - accuracy: 1.0000 - val_loss: 3.9433 - val_accuracy: 0.5238\n","Epoch 433/500\n","6/6 [==============================] - 0s 15ms/step - loss: 1.9772e-05 - accuracy: 1.0000 - val_loss: 3.9438 - val_accuracy: 0.5238\n","Epoch 434/500\n","6/6 [==============================] - 0s 14ms/step - loss: 1.9825e-05 - accuracy: 1.0000 - val_loss: 3.9527 - val_accuracy: 0.5238\n","Epoch 435/500\n","6/6 [==============================] - 0s 17ms/step - loss: 1.9659e-05 - accuracy: 1.0000 - val_loss: 3.9489 - val_accuracy: 0.5238\n","Epoch 436/500\n","6/6 [==============================] - 0s 17ms/step - loss: 1.9489e-05 - accuracy: 1.0000 - val_loss: 3.9526 - val_accuracy: 0.5238\n","Epoch 437/500\n","6/6 [==============================] - 0s 17ms/step - loss: 1.9423e-05 - accuracy: 1.0000 - val_loss: 3.9508 - val_accuracy: 0.5238\n","Epoch 438/500\n","6/6 [==============================] - 0s 15ms/step - loss: 1.9283e-05 - accuracy: 1.0000 - val_loss: 3.9518 - val_accuracy: 0.5238\n","Epoch 439/500\n","6/6 [==============================] - 0s 19ms/step - loss: 1.9121e-05 - accuracy: 1.0000 - val_loss: 3.9558 - val_accuracy: 0.5238\n","Epoch 440/500\n","6/6 [==============================] - 0s 18ms/step - loss: 1.9029e-05 - accuracy: 1.0000 - val_loss: 3.9595 - val_accuracy: 0.5238\n","Epoch 441/500\n","6/6 [==============================] - 0s 14ms/step - loss: 1.9069e-05 - accuracy: 1.0000 - val_loss: 3.9670 - val_accuracy: 0.5238\n","Epoch 442/500\n","6/6 [==============================] - 0s 18ms/step - loss: 1.8839e-05 - accuracy: 1.0000 - val_loss: 3.9666 - val_accuracy: 0.5238\n","Epoch 443/500\n","6/6 [==============================] - 0s 13ms/step - loss: 1.8717e-05 - accuracy: 1.0000 - val_loss: 3.9677 - val_accuracy: 0.5238\n","Epoch 444/500\n","6/6 [==============================] - 0s 14ms/step - loss: 1.8628e-05 - accuracy: 1.0000 - val_loss: 3.9670 - val_accuracy: 0.5238\n","Epoch 445/500\n","6/6 [==============================] - 0s 13ms/step - loss: 1.8592e-05 - accuracy: 1.0000 - val_loss: 3.9698 - val_accuracy: 0.5238\n","Epoch 446/500\n","6/6 [==============================] - 0s 14ms/step - loss: 1.8639e-05 - accuracy: 1.0000 - val_loss: 3.9646 - val_accuracy: 0.5238\n","Epoch 447/500\n","6/6 [==============================] - 0s 12ms/step - loss: 1.8363e-05 - accuracy: 1.0000 - val_loss: 3.9683 - val_accuracy: 0.5238\n","Epoch 448/500\n","6/6 [==============================] - 0s 14ms/step - loss: 1.8263e-05 - accuracy: 1.0000 - val_loss: 3.9715 - val_accuracy: 0.5238\n","Epoch 449/500\n","6/6 [==============================] - 0s 13ms/step - loss: 1.8269e-05 - accuracy: 1.0000 - val_loss: 3.9802 - val_accuracy: 0.5238\n","Epoch 450/500\n","6/6 [==============================] - 0s 15ms/step - loss: 1.8085e-05 - accuracy: 1.0000 - val_loss: 3.9829 - val_accuracy: 0.5238\n","Epoch 451/500\n","6/6 [==============================] - 0s 13ms/step - loss: 1.8038e-05 - accuracy: 1.0000 - val_loss: 3.9801 - val_accuracy: 0.5238\n","Epoch 452/500\n","6/6 [==============================] - 0s 15ms/step - loss: 1.7898e-05 - accuracy: 1.0000 - val_loss: 3.9838 - val_accuracy: 0.5238\n","Epoch 453/500\n","6/6 [==============================] - 0s 13ms/step - loss: 1.7790e-05 - accuracy: 1.0000 - val_loss: 3.9841 - val_accuracy: 0.5238\n","Epoch 454/500\n","6/6 [==============================] - 0s 13ms/step - loss: 1.7714e-05 - accuracy: 1.0000 - val_loss: 3.9851 - val_accuracy: 0.5238\n","Epoch 455/500\n","6/6 [==============================] - 0s 14ms/step - loss: 1.7609e-05 - accuracy: 1.0000 - val_loss: 3.9884 - val_accuracy: 0.5238\n","Epoch 456/500\n","6/6 [==============================] - 0s 14ms/step - loss: 1.7525e-05 - accuracy: 1.0000 - val_loss: 3.9916 - val_accuracy: 0.5238\n","Epoch 457/500\n","6/6 [==============================] - 0s 14ms/step - loss: 1.7450e-05 - accuracy: 1.0000 - val_loss: 3.9931 - val_accuracy: 0.5238\n","Epoch 458/500\n","6/6 [==============================] - 0s 13ms/step - loss: 1.7350e-05 - accuracy: 1.0000 - val_loss: 3.9980 - val_accuracy: 0.5238\n","Epoch 459/500\n","6/6 [==============================] - 0s 13ms/step - loss: 1.7304e-05 - accuracy: 1.0000 - val_loss: 4.0031 - val_accuracy: 0.5238\n","Epoch 460/500\n","6/6 [==============================] - 0s 13ms/step - loss: 1.7185e-05 - accuracy: 1.0000 - val_loss: 4.0021 - val_accuracy: 0.5238\n","Epoch 461/500\n","6/6 [==============================] - 0s 18ms/step - loss: 1.7084e-05 - accuracy: 1.0000 - val_loss: 4.0024 - val_accuracy: 0.5238\n","Epoch 462/500\n","6/6 [==============================] - 0s 16ms/step - loss: 1.6992e-05 - accuracy: 1.0000 - val_loss: 4.0034 - val_accuracy: 0.5238\n","Epoch 463/500\n","6/6 [==============================] - 0s 14ms/step - loss: 1.6906e-05 - accuracy: 1.0000 - val_loss: 4.0056 - val_accuracy: 0.5238\n","Epoch 464/500\n","6/6 [==============================] - 0s 16ms/step - loss: 1.6803e-05 - accuracy: 1.0000 - val_loss: 4.0076 - val_accuracy: 0.5238\n","Epoch 465/500\n","6/6 [==============================] - 0s 14ms/step - loss: 1.6755e-05 - accuracy: 1.0000 - val_loss: 4.0129 - val_accuracy: 0.5238\n","Epoch 466/500\n","6/6 [==============================] - 0s 13ms/step - loss: 1.6635e-05 - accuracy: 1.0000 - val_loss: 4.0133 - val_accuracy: 0.5238\n","Epoch 467/500\n","6/6 [==============================] - 0s 13ms/step - loss: 1.6699e-05 - accuracy: 1.0000 - val_loss: 4.0100 - val_accuracy: 0.5238\n","Epoch 468/500\n","6/6 [==============================] - 0s 14ms/step - loss: 1.6474e-05 - accuracy: 1.0000 - val_loss: 4.0132 - val_accuracy: 0.5238\n","Epoch 469/500\n","6/6 [==============================] - 0s 14ms/step - loss: 1.6398e-05 - accuracy: 1.0000 - val_loss: 4.0157 - val_accuracy: 0.5238\n","Epoch 470/500\n","6/6 [==============================] - 0s 12ms/step - loss: 1.6335e-05 - accuracy: 1.0000 - val_loss: 4.0214 - val_accuracy: 0.5238\n","Epoch 471/500\n","6/6 [==============================] - 0s 15ms/step - loss: 1.6245e-05 - accuracy: 1.0000 - val_loss: 4.0245 - val_accuracy: 0.5238\n","Epoch 472/500\n","6/6 [==============================] - 0s 13ms/step - loss: 1.6231e-05 - accuracy: 1.0000 - val_loss: 4.0229 - val_accuracy: 0.5238\n","Epoch 473/500\n","6/6 [==============================] - 0s 14ms/step - loss: 1.6102e-05 - accuracy: 1.0000 - val_loss: 4.0282 - val_accuracy: 0.5238\n","Epoch 474/500\n","6/6 [==============================] - 0s 14ms/step - loss: 1.6011e-05 - accuracy: 1.0000 - val_loss: 4.0305 - val_accuracy: 0.5238\n","Epoch 475/500\n","6/6 [==============================] - 0s 15ms/step - loss: 1.5928e-05 - accuracy: 1.0000 - val_loss: 4.0336 - val_accuracy: 0.5238\n","Epoch 476/500\n","6/6 [==============================] - 0s 14ms/step - loss: 1.5851e-05 - accuracy: 1.0000 - val_loss: 4.0357 - val_accuracy: 0.5238\n","Epoch 477/500\n","6/6 [==============================] - 0s 16ms/step - loss: 1.5849e-05 - accuracy: 1.0000 - val_loss: 4.0300 - val_accuracy: 0.5238\n","Epoch 478/500\n","6/6 [==============================] - 0s 13ms/step - loss: 1.5665e-05 - accuracy: 1.0000 - val_loss: 4.0326 - val_accuracy: 0.5238\n","Epoch 479/500\n","6/6 [==============================] - 0s 14ms/step - loss: 1.5676e-05 - accuracy: 1.0000 - val_loss: 4.0321 - val_accuracy: 0.5238\n","Epoch 480/500\n","6/6 [==============================] - 0s 13ms/step - loss: 1.5540e-05 - accuracy: 1.0000 - val_loss: 4.0378 - val_accuracy: 0.5238\n","Epoch 481/500\n","6/6 [==============================] - 0s 13ms/step - loss: 1.5472e-05 - accuracy: 1.0000 - val_loss: 4.0386 - val_accuracy: 0.5238\n","Epoch 482/500\n","6/6 [==============================] - 0s 16ms/step - loss: 1.5369e-05 - accuracy: 1.0000 - val_loss: 4.0427 - val_accuracy: 0.5238\n","Epoch 483/500\n","6/6 [==============================] - 0s 14ms/step - loss: 1.5280e-05 - accuracy: 1.0000 - val_loss: 4.0467 - val_accuracy: 0.5238\n","Epoch 484/500\n","6/6 [==============================] - 0s 17ms/step - loss: 1.5222e-05 - accuracy: 1.0000 - val_loss: 4.0491 - val_accuracy: 0.5238\n","Epoch 485/500\n","6/6 [==============================] - 0s 14ms/step - loss: 1.5192e-05 - accuracy: 1.0000 - val_loss: 4.0546 - val_accuracy: 0.5238\n","Epoch 486/500\n","6/6 [==============================] - 0s 14ms/step - loss: 1.5120e-05 - accuracy: 1.0000 - val_loss: 4.0521 - val_accuracy: 0.5238\n","Epoch 487/500\n","6/6 [==============================] - 0s 16ms/step - loss: 1.5036e-05 - accuracy: 1.0000 - val_loss: 4.0511 - val_accuracy: 0.5238\n","Epoch 488/500\n","6/6 [==============================] - 0s 13ms/step - loss: 1.4977e-05 - accuracy: 1.0000 - val_loss: 4.0514 - val_accuracy: 0.5238\n","Epoch 489/500\n","6/6 [==============================] - 0s 12ms/step - loss: 1.4854e-05 - accuracy: 1.0000 - val_loss: 4.0566 - val_accuracy: 0.5238\n","Epoch 490/500\n","6/6 [==============================] - 0s 16ms/step - loss: 1.4789e-05 - accuracy: 1.0000 - val_loss: 4.0598 - val_accuracy: 0.5238\n","Epoch 491/500\n","6/6 [==============================] - 0s 14ms/step - loss: 1.4700e-05 - accuracy: 1.0000 - val_loss: 4.0649 - val_accuracy: 0.5238\n","Epoch 492/500\n","6/6 [==============================] - 0s 14ms/step - loss: 1.4640e-05 - accuracy: 1.0000 - val_loss: 4.0660 - val_accuracy: 0.5238\n","Epoch 493/500\n","6/6 [==============================] - 0s 13ms/step - loss: 1.4560e-05 - accuracy: 1.0000 - val_loss: 4.0676 - val_accuracy: 0.5238\n","Epoch 494/500\n","6/6 [==============================] - 0s 13ms/step - loss: 1.4525e-05 - accuracy: 1.0000 - val_loss: 4.0660 - val_accuracy: 0.5238\n","Epoch 495/500\n","6/6 [==============================] - 0s 13ms/step - loss: 1.4454e-05 - accuracy: 1.0000 - val_loss: 4.0712 - val_accuracy: 0.5238\n","Epoch 496/500\n","6/6 [==============================] - 0s 17ms/step - loss: 1.4371e-05 - accuracy: 1.0000 - val_loss: 4.0690 - val_accuracy: 0.5238\n","Epoch 497/500\n","6/6 [==============================] - 0s 13ms/step - loss: 1.4340e-05 - accuracy: 1.0000 - val_loss: 4.0742 - val_accuracy: 0.5238\n","Epoch 498/500\n","6/6 [==============================] - 0s 13ms/step - loss: 1.4201e-05 - accuracy: 1.0000 - val_loss: 4.0737 - val_accuracy: 0.5238\n","Epoch 499/500\n","6/6 [==============================] - 0s 17ms/step - loss: 1.4210e-05 - accuracy: 1.0000 - val_loss: 4.0715 - val_accuracy: 0.5238\n","Epoch 500/500\n","6/6 [==============================] - 0s 13ms/step - loss: 1.4077e-05 - accuracy: 1.0000 - val_loss: 4.0759 - val_accuracy: 0.5238\n"]},{"output_type":"execute_result","data":{"text/plain":["<matplotlib.legend.Legend at 0x7f3e55b1ad90>"]},"metadata":{},"execution_count":92},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 360x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"-yLMfXSWfKVA"},"source":["### 4. test ###\n","Let us test their performance using our test dataset. The test dataset is never used to train the models, and reflects the acutual performance of the model when it is used in the general images.\n","\n","To evaluate the model , we can use\n","`cat_model.evaluate(test_x,test_y)`. "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4pyTS3HmHXFQ","outputId":"dacfd5fb-c3b0-417b-804d-7ce038d99170","executionInfo":{"status":"ok","timestamp":1643597439667,"user_tz":300,"elapsed":534,"user":{"displayName":"Ahmad Alshami","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01911245819879647322"}}},"source":["cat_model.evaluate(test_x,test_y)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2/2 [==============================] - 0s 10ms/step - loss: 4.0934 - accuracy: 0.6800\n"]},{"output_type":"execute_result","data":{"text/plain":["[4.093389987945557, 0.6800000071525574]"]},"metadata":{},"execution_count":93}]},{"cell_type":"markdown","metadata":{"id":"crWckG9I807Q"},"source":["The expected accuracy is higher than 0.7. If the accuracy is lower than 0.7, you may want to increase the epoch number, adjust the learning rate, and the regularizer weight, to achieve the goal. \n","\n","For your reference, I trained the model for 5 min to achieve that goal. \n","\n","If you have achieved the 0.7 goal, I would like to challenge you for the 0.8 accuracy for the test set. "]},{"cell_type":"markdown","source":["### 5- Adding Regularization ###\n","After enough training, you probably notice that while the training loss is very small, the validation loss is quite large. This is what we called **low bias high vairance** problem. We have several ways to deal with it, \n","1. L1/L2 regularization, \n","2. drop out, and \n","3. early stop. \n","\n","I would recommend you try the regularization first, because it's easy to use and usually works. \n","\n","To add regularization to the network, we only need to specify this option in the 'Dense' layer as follows.\n","\n","`tf.keras.layers.Dense(20,activation='relu', \n","                          kernel_initializer='glorot_uniform',\n","                          bias_initializer='zeros', \n","                          kernel_regularizer=tf.keras.regularizers.L2(0.01))`\n","\n","The parameter **kernel_regularizer=tf.keras.regularizers.L2(0.01)** says that we want an 'L2' regularizer with weight 0.01. A higher weight usually can reduce the validation loss more. But if the weight is too large, the training loss might redecus very slowly."],"metadata":{"id":"U61bqEXKOFq1"}},{"cell_type":"code","source":["tf.random.set_seed(1)\n","cat_model_regu=tf.keras.Sequential([\n","        tf.keras.layers.InputLayer(input_shape=(12288)), # how many elements are there in every training image?\n","    tf.keras.layers.Dense(50,activation='relu', # in layer 1, we will have 20 neurons and use 'relu' as the activation function\n","                            kernel_initializer='glorot_uniform', # we will randomly choose the initial weight using the 'glorot_uniform' method\n","                            bias_initializer='zeros'), # we will initialize all bias to be zeros.\n","    tf.keras.layers.Dense(20,activation='relu', # in layer 1, we will have 20 neurons and use 'relu' as the activation function\n","                            kernel_initializer='glorot_uniform', # we will randomly choose the initial weight using the 'glorot_uniform' method\n","                            bias_initializer='zeros'), # we will initialize all bias to be zeros.\n","    tf.keras.layers.Dense(10,activation='relu', # in layer 1, we will have 20 neurons and use 'relu' as the activation function\n","                            kernel_initializer='glorot_uniform', # we will randomly choose the initial weight using the 'glorot_uniform' method\n","                            bias_initializer='zeros'), # we will initialize all bias to be zeros.                        \n","    #please follow the example of layer 1 to add more hidden layers here. \n","    # End adding hidden layers \n","    tf.keras.layers.Dense(1,activation='sigmoid', \n","                            kernel_initializer='glorot_uniform',\n","                            bias_initializer='zeros', \n","                            kernel_regularizer=tf.keras.regularizers.L2(0.01)),\n","])\n","\n","cat_model_regu.summary()"],"metadata":{"id":"a2yXbuObOcKl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1643597637490,"user_tz":300,"elapsed":143,"user":{"displayName":"Ahmad Alshami","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01911245819879647322"}},"outputId":"dff7b5a8-c613-4424-ef70-7e839ecf8f91"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_11\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_42 (Dense)            (None, 50)                614450    \n","                                                                 \n"," dense_43 (Dense)            (None, 20)                1020      \n","                                                                 \n"," dense_44 (Dense)            (None, 10)                210       \n","                                                                 \n"," dense_45 (Dense)            (None, 1)                 11        \n","                                                                 \n","=================================================================\n","Total params: 615,691\n","Trainable params: 615,691\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["Now, you can compile and train the regularized neural network as before."],"metadata":{"id":"wFRAcU0oPJa8"}},{"cell_type":"code","source":["# start your code here\n","cat_model_regu.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),  # Optimizer please change \"None\" to some meaningful number here\n","    # Loss function to minimize\n","    loss=tf.keras.losses.BinaryCrossentropy(),\n","    # List of metrics to monitor\n","    metrics=['accuracy'],\n","                 )\n","# end your code here. "],"metadata":{"id":"WBDncfdhPMiL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# start your code here\n","history_regu = cat_model_regu.fit(\n","    train_x, # input data\n","    train_y, # real output data\n","    validation_split=0.1, # this number is usually betwwen 0 and 0.3. It is the portion used as validation data, \n","    epochs=500, # how many iterations do you want to train your model? Your data will be reused to train the model for the number of epochs. I trained 5 min for this model\n",")\n","# end your code here\n","\n","plt.figure()\n","plt.plot(history_regu.history['loss'])\n","plt.plot(history_regu.history['val_loss'])\n","plt.legend(['loss','val_loss'])"],"metadata":{"id":"7ykpmUmDPWTl","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1643597686324,"user_tz":300,"elapsed":44907,"user":{"displayName":"Ahmad Alshami","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01911245819879647322"}},"outputId":"b863f5de-b24a-4cc8-b052-69c7fa5f72b8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/500\n","6/6 [==============================] - 1s 44ms/step - loss: 7.4231 - accuracy: 0.5798 - val_loss: 3.8659 - val_accuracy: 0.1905\n","Epoch 2/500\n","6/6 [==============================] - 0s 13ms/step - loss: 2.1508 - accuracy: 0.4840 - val_loss: 3.4167 - val_accuracy: 0.1905\n","Epoch 3/500\n","6/6 [==============================] - 0s 15ms/step - loss: 2.3186 - accuracy: 0.4947 - val_loss: 0.7598 - val_accuracy: 0.7619\n","Epoch 4/500\n","6/6 [==============================] - 0s 13ms/step - loss: 1.1985 - accuracy: 0.5000 - val_loss: 0.9526 - val_accuracy: 0.7619\n","Epoch 5/500\n","6/6 [==============================] - 0s 12ms/step - loss: 1.0365 - accuracy: 0.6064 - val_loss: 1.0898 - val_accuracy: 0.7619\n","Epoch 6/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.9213 - accuracy: 0.5904 - val_loss: 0.5856 - val_accuracy: 0.7619\n","Epoch 7/500\n","6/6 [==============================] - 0s 14ms/step - loss: 0.6405 - accuracy: 0.7128 - val_loss: 0.8661 - val_accuracy: 0.4286\n","Epoch 8/500\n","6/6 [==============================] - 0s 14ms/step - loss: 0.6430 - accuracy: 0.6330 - val_loss: 0.6768 - val_accuracy: 0.5238\n","Epoch 9/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.6485 - accuracy: 0.6702 - val_loss: 0.5919 - val_accuracy: 0.7619\n","Epoch 10/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.6099 - accuracy: 0.6755 - val_loss: 0.5943 - val_accuracy: 0.7619\n","Epoch 11/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.6122 - accuracy: 0.6649 - val_loss: 0.6258 - val_accuracy: 0.6667\n","Epoch 12/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.6674 - accuracy: 0.6223 - val_loss: 0.7698 - val_accuracy: 0.4762\n","Epoch 13/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.5487 - accuracy: 0.7447 - val_loss: 0.6443 - val_accuracy: 0.6667\n","Epoch 14/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.5187 - accuracy: 0.7394 - val_loss: 0.6545 - val_accuracy: 0.6190\n","Epoch 15/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.5173 - accuracy: 0.7181 - val_loss: 0.6998 - val_accuracy: 0.4762\n","Epoch 16/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.5281 - accuracy: 0.7500 - val_loss: 0.6547 - val_accuracy: 0.6190\n","Epoch 17/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.4888 - accuracy: 0.7713 - val_loss: 0.7367 - val_accuracy: 0.5238\n","Epoch 18/500\n","6/6 [==============================] - 0s 16ms/step - loss: 0.4824 - accuracy: 0.7819 - val_loss: 0.6994 - val_accuracy: 0.4762\n","Epoch 19/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.4915 - accuracy: 0.7713 - val_loss: 0.6911 - val_accuracy: 0.4762\n","Epoch 20/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.5867 - accuracy: 0.7128 - val_loss: 0.6727 - val_accuracy: 0.7619\n","Epoch 21/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.4665 - accuracy: 0.8032 - val_loss: 0.6297 - val_accuracy: 0.7143\n","Epoch 22/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.4477 - accuracy: 0.7819 - val_loss: 0.7584 - val_accuracy: 0.4762\n","Epoch 23/500\n","6/6 [==============================] - 0s 11ms/step - loss: 0.4067 - accuracy: 0.8457 - val_loss: 0.6791 - val_accuracy: 0.5238\n","Epoch 24/500\n","6/6 [==============================] - 0s 11ms/step - loss: 0.4229 - accuracy: 0.8191 - val_loss: 0.6509 - val_accuracy: 0.7619\n","Epoch 25/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.4092 - accuracy: 0.8351 - val_loss: 0.6497 - val_accuracy: 0.7619\n","Epoch 26/500\n","6/6 [==============================] - 0s 11ms/step - loss: 0.3517 - accuracy: 0.8723 - val_loss: 0.8686 - val_accuracy: 0.4286\n","Epoch 27/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.3981 - accuracy: 0.8245 - val_loss: 1.0379 - val_accuracy: 0.4762\n","Epoch 28/500\n","6/6 [==============================] - 0s 14ms/step - loss: 0.4136 - accuracy: 0.8138 - val_loss: 0.7078 - val_accuracy: 0.4762\n","Epoch 29/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.3317 - accuracy: 0.8670 - val_loss: 0.7794 - val_accuracy: 0.7619\n","Epoch 30/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.5804 - accuracy: 0.7500 - val_loss: 1.0399 - val_accuracy: 0.7619\n","Epoch 31/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.8087 - accuracy: 0.6968 - val_loss: 0.6211 - val_accuracy: 0.7619\n","Epoch 32/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.5300 - accuracy: 0.6543 - val_loss: 0.7397 - val_accuracy: 0.4762\n","Epoch 33/500\n","6/6 [==============================] - 0s 11ms/step - loss: 0.4764 - accuracy: 0.7660 - val_loss: 0.7970 - val_accuracy: 0.4286\n","Epoch 34/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.3683 - accuracy: 0.8617 - val_loss: 0.7836 - val_accuracy: 0.7619\n","Epoch 35/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.3339 - accuracy: 0.8777 - val_loss: 1.2110 - val_accuracy: 0.4286\n","Epoch 36/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.4603 - accuracy: 0.8138 - val_loss: 0.9387 - val_accuracy: 0.7619\n","Epoch 37/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.4474 - accuracy: 0.8032 - val_loss: 0.8301 - val_accuracy: 0.6667\n","Epoch 38/500\n","6/6 [==============================] - 0s 16ms/step - loss: 0.3517 - accuracy: 0.8617 - val_loss: 0.9165 - val_accuracy: 0.4286\n","Epoch 39/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.3559 - accuracy: 0.8457 - val_loss: 0.7675 - val_accuracy: 0.6190\n","Epoch 40/500\n","6/6 [==============================] - 0s 11ms/step - loss: 0.2778 - accuracy: 0.8936 - val_loss: 0.7604 - val_accuracy: 0.6190\n","Epoch 41/500\n","6/6 [==============================] - 0s 14ms/step - loss: 0.2887 - accuracy: 0.8564 - val_loss: 0.7659 - val_accuracy: 0.5714\n","Epoch 42/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.1981 - accuracy: 0.9415 - val_loss: 0.8569 - val_accuracy: 0.5238\n","Epoch 43/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.1897 - accuracy: 0.9415 - val_loss: 1.1980 - val_accuracy: 0.4286\n","Epoch 44/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.2977 - accuracy: 0.8670 - val_loss: 0.9760 - val_accuracy: 0.7143\n","Epoch 45/500\n","6/6 [==============================] - 0s 14ms/step - loss: 0.2187 - accuracy: 0.9149 - val_loss: 1.0611 - val_accuracy: 0.5714\n","Epoch 46/500\n","6/6 [==============================] - 0s 15ms/step - loss: 0.1355 - accuracy: 0.9521 - val_loss: 1.1581 - val_accuracy: 0.4762\n","Epoch 47/500\n","6/6 [==============================] - 0s 14ms/step - loss: 0.1376 - accuracy: 0.9521 - val_loss: 0.9723 - val_accuracy: 0.5238\n","Epoch 48/500\n","6/6 [==============================] - 0s 14ms/step - loss: 0.1528 - accuracy: 0.9521 - val_loss: 1.1098 - val_accuracy: 0.4286\n","Epoch 49/500\n","6/6 [==============================] - 0s 14ms/step - loss: 0.1110 - accuracy: 0.9681 - val_loss: 1.2911 - val_accuracy: 0.5714\n","Epoch 50/500\n","6/6 [==============================] - 0s 14ms/step - loss: 0.1537 - accuracy: 0.9468 - val_loss: 1.0835 - val_accuracy: 0.5238\n","Epoch 51/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.4985 - accuracy: 0.8457 - val_loss: 1.7347 - val_accuracy: 0.4286\n","Epoch 52/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.2732 - accuracy: 0.8830 - val_loss: 1.6466 - val_accuracy: 0.5238\n","Epoch 53/500\n","6/6 [==============================] - 0s 16ms/step - loss: 0.1202 - accuracy: 0.9628 - val_loss: 1.4040 - val_accuracy: 0.6190\n","Epoch 54/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.2094 - accuracy: 0.9149 - val_loss: 1.2537 - val_accuracy: 0.3810\n","Epoch 55/500\n","6/6 [==============================] - 0s 14ms/step - loss: 0.2778 - accuracy: 0.8830 - val_loss: 1.4300 - val_accuracy: 0.3810\n","Epoch 56/500\n","6/6 [==============================] - 0s 14ms/step - loss: 0.2999 - accuracy: 0.8670 - val_loss: 2.3191 - val_accuracy: 0.2857\n","Epoch 57/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.3273 - accuracy: 0.8883 - val_loss: 1.6708 - val_accuracy: 0.3333\n","Epoch 58/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.2629 - accuracy: 0.9043 - val_loss: 1.3308 - val_accuracy: 0.4762\n","Epoch 59/500\n","6/6 [==============================] - 0s 11ms/step - loss: 0.1565 - accuracy: 0.9574 - val_loss: 1.0941 - val_accuracy: 0.6190\n","Epoch 60/500\n","6/6 [==============================] - 0s 15ms/step - loss: 0.1644 - accuracy: 0.9309 - val_loss: 1.0524 - val_accuracy: 0.5714\n","Epoch 61/500\n","6/6 [==============================] - 0s 15ms/step - loss: 0.1624 - accuracy: 0.9628 - val_loss: 1.1155 - val_accuracy: 0.6190\n","Epoch 62/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.1170 - accuracy: 0.9787 - val_loss: 1.1852 - val_accuracy: 0.5238\n","Epoch 63/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0858 - accuracy: 0.9840 - val_loss: 1.3468 - val_accuracy: 0.5238\n","Epoch 64/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0628 - accuracy: 0.9894 - val_loss: 1.3258 - val_accuracy: 0.5238\n","Epoch 65/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0515 - accuracy: 0.9947 - val_loss: 1.2210 - val_accuracy: 0.5238\n","Epoch 66/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0439 - accuracy: 1.0000 - val_loss: 1.2146 - val_accuracy: 0.4762\n","Epoch 67/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0429 - accuracy: 1.0000 - val_loss: 1.4316 - val_accuracy: 0.4286\n","Epoch 68/500\n","6/6 [==============================] - 0s 11ms/step - loss: 0.0645 - accuracy: 0.9894 - val_loss: 1.6573 - val_accuracy: 0.3333\n","Epoch 69/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0791 - accuracy: 0.9787 - val_loss: 1.8700 - val_accuracy: 0.3810\n","Epoch 70/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.1847 - accuracy: 0.9255 - val_loss: 1.5838 - val_accuracy: 0.3810\n","Epoch 71/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.1577 - accuracy: 0.9521 - val_loss: 2.1768 - val_accuracy: 0.2857\n","Epoch 72/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.2389 - accuracy: 0.9149 - val_loss: 1.6804 - val_accuracy: 0.4286\n","Epoch 73/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0749 - accuracy: 0.9840 - val_loss: 1.4969 - val_accuracy: 0.4762\n","Epoch 74/500\n","6/6 [==============================] - 0s 15ms/step - loss: 0.0521 - accuracy: 0.9947 - val_loss: 1.6157 - val_accuracy: 0.4286\n","Epoch 75/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0950 - accuracy: 0.9734 - val_loss: 1.9611 - val_accuracy: 0.3333\n","Epoch 76/500\n","6/6 [==============================] - 0s 15ms/step - loss: 0.1395 - accuracy: 0.9468 - val_loss: 2.0898 - val_accuracy: 0.2381\n","Epoch 77/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.1925 - accuracy: 0.9255 - val_loss: 1.9383 - val_accuracy: 0.3810\n","Epoch 78/500\n","6/6 [==============================] - 0s 17ms/step - loss: 0.1372 - accuracy: 0.9574 - val_loss: 1.9193 - val_accuracy: 0.3333\n","Epoch 79/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0647 - accuracy: 0.9787 - val_loss: 2.0078 - val_accuracy: 0.3810\n","Epoch 80/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.1039 - accuracy: 0.9521 - val_loss: 1.9432 - val_accuracy: 0.3810\n","Epoch 81/500\n","6/6 [==============================] - 0s 14ms/step - loss: 0.1291 - accuracy: 0.9468 - val_loss: 1.7701 - val_accuracy: 0.3810\n","Epoch 82/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.1276 - accuracy: 0.9574 - val_loss: 1.3855 - val_accuracy: 0.4286\n","Epoch 83/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.1484 - accuracy: 0.9255 - val_loss: 1.9739 - val_accuracy: 0.4762\n","Epoch 84/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.3742 - accuracy: 0.9096 - val_loss: 1.5348 - val_accuracy: 0.4762\n","Epoch 85/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.2623 - accuracy: 0.8830 - val_loss: 1.2921 - val_accuracy: 0.6190\n","Epoch 86/500\n","6/6 [==============================] - 0s 14ms/step - loss: 0.0863 - accuracy: 0.9681 - val_loss: 1.5366 - val_accuracy: 0.6667\n","Epoch 87/500\n","6/6 [==============================] - 0s 14ms/step - loss: 0.0680 - accuracy: 0.9894 - val_loss: 1.4338 - val_accuracy: 0.4762\n","Epoch 88/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0483 - accuracy: 0.9947 - val_loss: 1.5515 - val_accuracy: 0.4762\n","Epoch 89/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0394 - accuracy: 1.0000 - val_loss: 1.4442 - val_accuracy: 0.4762\n","Epoch 90/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0249 - accuracy: 1.0000 - val_loss: 1.4727 - val_accuracy: 0.5238\n","Epoch 91/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0223 - accuracy: 1.0000 - val_loss: 1.5501 - val_accuracy: 0.4286\n","Epoch 92/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0435 - accuracy: 0.9840 - val_loss: 1.4734 - val_accuracy: 0.6190\n","Epoch 93/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0462 - accuracy: 0.9894 - val_loss: 1.6859 - val_accuracy: 0.6190\n","Epoch 94/500\n","6/6 [==============================] - 0s 15ms/step - loss: 0.0514 - accuracy: 0.9840 - val_loss: 1.8438 - val_accuracy: 0.4286\n","Epoch 95/500\n","6/6 [==============================] - 0s 11ms/step - loss: 0.0320 - accuracy: 1.0000 - val_loss: 1.4237 - val_accuracy: 0.4762\n","Epoch 96/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0289 - accuracy: 0.9947 - val_loss: 1.4472 - val_accuracy: 0.6190\n","Epoch 97/500\n","6/6 [==============================] - 0s 14ms/step - loss: 0.0318 - accuracy: 1.0000 - val_loss: 1.6738 - val_accuracy: 0.4286\n","Epoch 98/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0173 - accuracy: 1.0000 - val_loss: 1.6023 - val_accuracy: 0.5238\n","Epoch 99/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0194 - accuracy: 1.0000 - val_loss: 1.6109 - val_accuracy: 0.4762\n","Epoch 100/500\n","6/6 [==============================] - 0s 14ms/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 1.6628 - val_accuracy: 0.4762\n","Epoch 101/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0169 - accuracy: 1.0000 - val_loss: 1.5949 - val_accuracy: 0.5238\n","Epoch 102/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 1.5882 - val_accuracy: 0.4762\n","Epoch 103/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 1.6395 - val_accuracy: 0.4762\n","Epoch 104/500\n","6/6 [==============================] - 0s 11ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 1.6899 - val_accuracy: 0.4762\n","Epoch 105/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 1.7208 - val_accuracy: 0.4762\n","Epoch 106/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 1.7134 - val_accuracy: 0.4762\n","Epoch 107/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 1.7092 - val_accuracy: 0.4762\n","Epoch 108/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 1.7429 - val_accuracy: 0.4762\n","Epoch 109/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 1.7521 - val_accuracy: 0.4762\n","Epoch 110/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 1.7828 - val_accuracy: 0.4762\n","Epoch 111/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 1.8808 - val_accuracy: 0.4762\n","Epoch 112/500\n","6/6 [==============================] - 0s 14ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 1.9670 - val_accuracy: 0.4762\n","Epoch 113/500\n","6/6 [==============================] - 0s 17ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 2.2202 - val_accuracy: 0.4762\n","Epoch 114/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 2.6098 - val_accuracy: 0.4762\n","Epoch 115/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 3.0469 - val_accuracy: 0.4762\n","Epoch 116/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 3.2832 - val_accuracy: 0.5238\n","Epoch 117/500\n","6/6 [==============================] - 0s 11ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 3.3144 - val_accuracy: 0.5238\n","Epoch 118/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 3.3413 - val_accuracy: 0.5238\n","Epoch 119/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 3.4116 - val_accuracy: 0.4762\n","Epoch 120/500\n","6/6 [==============================] - 0s 16ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 3.4701 - val_accuracy: 0.4762\n","Epoch 121/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 3.5138 - val_accuracy: 0.4762\n","Epoch 122/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 3.5481 - val_accuracy: 0.4762\n","Epoch 123/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 3.5760 - val_accuracy: 0.4762\n","Epoch 124/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 3.5954 - val_accuracy: 0.4762\n","Epoch 125/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 3.6245 - val_accuracy: 0.4762\n","Epoch 126/500\n","6/6 [==============================] - 0s 15ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 3.6578 - val_accuracy: 0.4762\n","Epoch 127/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 3.6966 - val_accuracy: 0.4762\n","Epoch 128/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 3.7314 - val_accuracy: 0.4762\n","Epoch 129/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 3.7583 - val_accuracy: 0.4762\n","Epoch 130/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 3.7947 - val_accuracy: 0.4762\n","Epoch 131/500\n","6/6 [==============================] - 0s 14ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 3.8175 - val_accuracy: 0.4762\n","Epoch 132/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 3.8416 - val_accuracy: 0.4762\n","Epoch 133/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 3.8645 - val_accuracy: 0.4762\n","Epoch 134/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 3.8894 - val_accuracy: 0.4762\n","Epoch 135/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 3.9164 - val_accuracy: 0.4762\n","Epoch 136/500\n","6/6 [==============================] - 0s 11ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 3.9611 - val_accuracy: 0.4762\n","Epoch 137/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 3.9806 - val_accuracy: 0.4762\n","Epoch 138/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 4.0033 - val_accuracy: 0.4762\n","Epoch 139/500\n","6/6 [==============================] - 0s 14ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 4.0272 - val_accuracy: 0.4762\n","Epoch 140/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 4.0533 - val_accuracy: 0.4762\n","Epoch 141/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 4.0792 - val_accuracy: 0.4762\n","Epoch 142/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 4.1072 - val_accuracy: 0.4762\n","Epoch 143/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 4.1252 - val_accuracy: 0.4762\n","Epoch 144/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 4.1396 - val_accuracy: 0.4762\n","Epoch 145/500\n","6/6 [==============================] - 0s 11ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 4.1588 - val_accuracy: 0.4762\n","Epoch 146/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 4.1766 - val_accuracy: 0.4762\n","Epoch 147/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 4.1965 - val_accuracy: 0.4762\n","Epoch 148/500\n","6/6 [==============================] - 0s 15ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 4.2142 - val_accuracy: 0.4762\n","Epoch 149/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 4.2328 - val_accuracy: 0.4762\n","Epoch 150/500\n","6/6 [==============================] - 0s 17ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 4.2508 - val_accuracy: 0.4762\n","Epoch 151/500\n","6/6 [==============================] - 0s 18ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 4.2660 - val_accuracy: 0.4762\n","Epoch 152/500\n","6/6 [==============================] - 0s 16ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 4.2734 - val_accuracy: 0.4762\n","Epoch 153/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 4.2864 - val_accuracy: 0.4762\n","Epoch 154/500\n","6/6 [==============================] - 0s 17ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 4.3032 - val_accuracy: 0.4762\n","Epoch 155/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 4.3150 - val_accuracy: 0.4762\n","Epoch 156/500\n","6/6 [==============================] - 0s 16ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 4.3291 - val_accuracy: 0.4762\n","Epoch 157/500\n","6/6 [==============================] - 0s 15ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 4.3424 - val_accuracy: 0.4762\n","Epoch 158/500\n","6/6 [==============================] - 0s 14ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 4.3521 - val_accuracy: 0.4762\n","Epoch 159/500\n","6/6 [==============================] - 0s 14ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 4.3632 - val_accuracy: 0.4762\n","Epoch 160/500\n","6/6 [==============================] - 0s 17ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 4.3771 - val_accuracy: 0.4762\n","Epoch 161/500\n","6/6 [==============================] - 0s 17ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 4.3857 - val_accuracy: 0.4762\n","Epoch 162/500\n","6/6 [==============================] - 0s 14ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 4.3998 - val_accuracy: 0.4762\n","Epoch 163/500\n","6/6 [==============================] - 0s 14ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 4.3969 - val_accuracy: 0.4762\n","Epoch 164/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 4.4005 - val_accuracy: 0.4762\n","Epoch 165/500\n","6/6 [==============================] - 0s 17ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 4.4197 - val_accuracy: 0.4762\n","Epoch 166/500\n","6/6 [==============================] - 0s 16ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 4.4405 - val_accuracy: 0.4762\n","Epoch 167/500\n","6/6 [==============================] - 0s 14ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 4.4523 - val_accuracy: 0.4762\n","Epoch 168/500\n","6/6 [==============================] - 0s 14ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 4.4625 - val_accuracy: 0.4762\n","Epoch 169/500\n","6/6 [==============================] - 0s 17ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 4.4784 - val_accuracy: 0.4762\n","Epoch 170/500\n","6/6 [==============================] - 0s 16ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 4.4776 - val_accuracy: 0.4762\n","Epoch 171/500\n","6/6 [==============================] - 0s 14ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 4.4980 - val_accuracy: 0.4762\n","Epoch 172/500\n","6/6 [==============================] - 0s 19ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 4.5039 - val_accuracy: 0.4762\n","Epoch 173/500\n","6/6 [==============================] - 0s 14ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 4.4916 - val_accuracy: 0.4762\n","Epoch 174/500\n","6/6 [==============================] - 0s 19ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 4.5159 - val_accuracy: 0.4762\n","Epoch 175/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 4.5372 - val_accuracy: 0.4762\n","Epoch 176/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 4.5537 - val_accuracy: 0.4762\n","Epoch 177/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 4.5472 - val_accuracy: 0.4762\n","Epoch 178/500\n","6/6 [==============================] - 0s 14ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 4.5439 - val_accuracy: 0.4762\n","Epoch 179/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 4.5417 - val_accuracy: 0.4762\n","Epoch 180/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 4.5639 - val_accuracy: 0.4762\n","Epoch 181/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 4.5698 - val_accuracy: 0.4762\n","Epoch 182/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 4.5898 - val_accuracy: 0.4762\n","Epoch 183/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 4.5916 - val_accuracy: 0.4762\n","Epoch 184/500\n","6/6 [==============================] - 0s 16ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 4.5945 - val_accuracy: 0.4762\n","Epoch 185/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 4.6001 - val_accuracy: 0.4762\n","Epoch 186/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 4.6200 - val_accuracy: 0.4762\n","Epoch 187/500\n","6/6 [==============================] - 0s 11ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 4.6255 - val_accuracy: 0.4762\n","Epoch 188/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 4.6361 - val_accuracy: 0.4762\n","Epoch 189/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 4.6206 - val_accuracy: 0.4762\n","Epoch 190/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 4.6285 - val_accuracy: 0.4762\n","Epoch 191/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 4.6596 - val_accuracy: 0.4762\n","Epoch 192/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 4.6451 - val_accuracy: 0.4762\n","Epoch 193/500\n","6/6 [==============================] - 0s 17ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 4.6643 - val_accuracy: 0.4762\n","Epoch 194/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 4.6744 - val_accuracy: 0.4762\n","Epoch 195/500\n","6/6 [==============================] - 0s 14ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 4.6704 - val_accuracy: 0.4762\n","Epoch 196/500\n","6/6 [==============================] - 0s 18ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 4.6732 - val_accuracy: 0.4762\n","Epoch 197/500\n","6/6 [==============================] - 0s 14ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 4.6828 - val_accuracy: 0.4762\n","Epoch 198/500\n","6/6 [==============================] - 0s 15ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 4.6983 - val_accuracy: 0.4762\n","Epoch 199/500\n","6/6 [==============================] - 0s 16ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 4.7113 - val_accuracy: 0.4762\n","Epoch 200/500\n","6/6 [==============================] - 0s 17ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 4.7194 - val_accuracy: 0.4762\n","Epoch 201/500\n","6/6 [==============================] - 0s 14ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 4.7098 - val_accuracy: 0.4762\n","Epoch 202/500\n","6/6 [==============================] - 0s 14ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 4.7030 - val_accuracy: 0.4762\n","Epoch 203/500\n","6/6 [==============================] - 0s 14ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 4.7214 - val_accuracy: 0.4762\n","Epoch 204/500\n","6/6 [==============================] - 0s 16ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 4.7287 - val_accuracy: 0.4762\n","Epoch 205/500\n","6/6 [==============================] - 0s 15ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 4.7476 - val_accuracy: 0.4762\n","Epoch 206/500\n","6/6 [==============================] - 0s 14ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 4.7327 - val_accuracy: 0.4762\n","Epoch 207/500\n","6/6 [==============================] - 0s 19ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 4.7376 - val_accuracy: 0.4762\n","Epoch 208/500\n","6/6 [==============================] - 0s 14ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 4.7576 - val_accuracy: 0.4762\n","Epoch 209/500\n","6/6 [==============================] - 0s 16ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 4.7572 - val_accuracy: 0.4762\n","Epoch 210/500\n","6/6 [==============================] - 0s 14ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 4.7585 - val_accuracy: 0.4762\n","Epoch 211/500\n","6/6 [==============================] - 0s 16ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 4.7560 - val_accuracy: 0.4762\n","Epoch 212/500\n","6/6 [==============================] - 0s 17ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 4.7598 - val_accuracy: 0.4762\n","Epoch 213/500\n","6/6 [==============================] - 0s 14ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 4.7679 - val_accuracy: 0.4762\n","Epoch 214/500\n","6/6 [==============================] - 0s 21ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 4.7636 - val_accuracy: 0.4762\n","Epoch 215/500\n","6/6 [==============================] - 0s 14ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 4.7610 - val_accuracy: 0.4762\n","Epoch 216/500\n","6/6 [==============================] - 0s 17ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 4.7765 - val_accuracy: 0.4762\n","Epoch 217/500\n","6/6 [==============================] - 0s 19ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 4.7894 - val_accuracy: 0.4762\n","Epoch 218/500\n","6/6 [==============================] - 0s 16ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 4.8015 - val_accuracy: 0.4762\n","Epoch 219/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 4.7793 - val_accuracy: 0.4762\n","Epoch 220/500\n","6/6 [==============================] - 0s 16ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 4.7849 - val_accuracy: 0.4762\n","Epoch 221/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 4.7866 - val_accuracy: 0.4762\n","Epoch 222/500\n","6/6 [==============================] - 0s 16ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 4.8050 - val_accuracy: 0.4762\n","Epoch 223/500\n","6/6 [==============================] - 0s 17ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 4.8208 - val_accuracy: 0.4762\n","Epoch 224/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 4.8183 - val_accuracy: 0.4762\n","Epoch 225/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 4.8179 - val_accuracy: 0.4762\n","Epoch 226/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 4.8071 - val_accuracy: 0.4762\n","Epoch 227/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 4.8091 - val_accuracy: 0.4762\n","Epoch 228/500\n","6/6 [==============================] - 0s 15ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 4.8064 - val_accuracy: 0.4762\n","Epoch 229/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 4.8198 - val_accuracy: 0.4762\n","Epoch 230/500\n","6/6 [==============================] - 0s 14ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 4.8189 - val_accuracy: 0.4762\n","Epoch 231/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 4.8269 - val_accuracy: 0.4762\n","Epoch 232/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 4.8433 - val_accuracy: 0.4762\n","Epoch 233/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 4.8257 - val_accuracy: 0.4762\n","Epoch 234/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 4.8181 - val_accuracy: 0.4762\n","Epoch 235/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 4.8048 - val_accuracy: 0.4762\n","Epoch 236/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 4.8191 - val_accuracy: 0.4762\n","Epoch 237/500\n","6/6 [==============================] - 0s 14ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 4.8418 - val_accuracy: 0.4762\n","Epoch 238/500\n","6/6 [==============================] - 0s 17ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 4.8305 - val_accuracy: 0.4762\n","Epoch 239/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 4.8395 - val_accuracy: 0.4762\n","Epoch 240/500\n","6/6 [==============================] - 0s 19ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 4.8461 - val_accuracy: 0.4762\n","Epoch 241/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 4.8522 - val_accuracy: 0.4762\n","Epoch 242/500\n","6/6 [==============================] - 0s 14ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 4.8684 - val_accuracy: 0.4762\n","Epoch 243/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 4.8593 - val_accuracy: 0.4762\n","Epoch 244/500\n","6/6 [==============================] - 0s 14ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 4.8524 - val_accuracy: 0.4762\n","Epoch 245/500\n","6/6 [==============================] - 0s 17ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 4.8392 - val_accuracy: 0.4762\n","Epoch 246/500\n","6/6 [==============================] - 0s 16ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 4.8450 - val_accuracy: 0.4762\n","Epoch 247/500\n","6/6 [==============================] - 0s 14ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 4.8575 - val_accuracy: 0.4762\n","Epoch 248/500\n","6/6 [==============================] - 0s 14ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 4.8591 - val_accuracy: 0.4762\n","Epoch 249/500\n","6/6 [==============================] - 0s 14ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 4.8762 - val_accuracy: 0.4762\n","Epoch 250/500\n","6/6 [==============================] - 0s 18ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 4.8788 - val_accuracy: 0.4762\n","Epoch 251/500\n","6/6 [==============================] - 0s 18ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 4.8584 - val_accuracy: 0.4762\n","Epoch 252/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 4.8528 - val_accuracy: 0.4762\n","Epoch 253/500\n","6/6 [==============================] - 0s 14ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 4.8684 - val_accuracy: 0.4762\n","Epoch 254/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 4.8809 - val_accuracy: 0.4762\n","Epoch 255/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 4.8730 - val_accuracy: 0.4762\n","Epoch 256/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 4.8867 - val_accuracy: 0.4762\n","Epoch 257/500\n","6/6 [==============================] - 0s 16ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 4.8971 - val_accuracy: 0.4762\n","Epoch 258/500\n","6/6 [==============================] - 0s 14ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 4.8634 - val_accuracy: 0.4762\n","Epoch 259/500\n","6/6 [==============================] - 0s 14ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 4.8507 - val_accuracy: 0.4762\n","Epoch 260/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 4.8648 - val_accuracy: 0.4762\n","Epoch 261/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 4.8803 - val_accuracy: 0.4762\n","Epoch 262/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 4.9031 - val_accuracy: 0.4762\n","Epoch 263/500\n","6/6 [==============================] - 0s 14ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 4.8819 - val_accuracy: 0.4762\n","Epoch 264/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 4.8754 - val_accuracy: 0.4762\n","Epoch 265/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 4.8829 - val_accuracy: 0.4762\n","Epoch 266/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 4.8797 - val_accuracy: 0.4762\n","Epoch 267/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 4.8766 - val_accuracy: 0.4762\n","Epoch 268/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 4.8842 - val_accuracy: 0.4762\n","Epoch 269/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 4.8827 - val_accuracy: 0.4762\n","Epoch 270/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 4.8937 - val_accuracy: 0.4762\n","Epoch 271/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 4.8888 - val_accuracy: 0.4762\n","Epoch 272/500\n","6/6 [==============================] - 0s 16ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 4.8796 - val_accuracy: 0.4762\n","Epoch 273/500\n","6/6 [==============================] - 0s 17ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 4.8850 - val_accuracy: 0.4762\n","Epoch 274/500\n","6/6 [==============================] - 0s 14ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 4.8781 - val_accuracy: 0.4762\n","Epoch 275/500\n","6/6 [==============================] - 0s 18ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 4.8854 - val_accuracy: 0.4762\n","Epoch 276/500\n","6/6 [==============================] - 0s 14ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 4.8884 - val_accuracy: 0.4762\n","Epoch 277/500\n","6/6 [==============================] - 0s 14ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 4.8878 - val_accuracy: 0.4762\n","Epoch 278/500\n","6/6 [==============================] - 0s 15ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 4.8998 - val_accuracy: 0.4762\n","Epoch 279/500\n","6/6 [==============================] - 0s 14ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 4.9027 - val_accuracy: 0.4762\n","Epoch 280/500\n","6/6 [==============================] - 0s 14ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 4.8937 - val_accuracy: 0.4762\n","Epoch 281/500\n","6/6 [==============================] - 0s 18ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 4.8916 - val_accuracy: 0.4762\n","Epoch 282/500\n","6/6 [==============================] - 0s 14ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 4.8891 - val_accuracy: 0.4762\n","Epoch 283/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 4.8916 - val_accuracy: 0.4762\n","Epoch 284/500\n","6/6 [==============================] - 0s 14ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 4.8937 - val_accuracy: 0.4762\n","Epoch 285/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 4.8932 - val_accuracy: 0.4762\n","Epoch 286/500\n","6/6 [==============================] - 0s 16ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 4.8777 - val_accuracy: 0.4762\n","Epoch 287/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 5.1187 - val_accuracy: 0.4762\n","Epoch 288/500\n","6/6 [==============================] - 0s 14ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 5.0973 - val_accuracy: 0.4762\n","Epoch 289/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 5.0561 - val_accuracy: 0.4762\n","Epoch 290/500\n","6/6 [==============================] - 0s 14ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 5.0112 - val_accuracy: 0.4762\n","Epoch 291/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 5.0004 - val_accuracy: 0.4762\n","Epoch 292/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 5.0152 - val_accuracy: 0.4762\n","Epoch 293/500\n","6/6 [==============================] - 0s 14ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 5.0357 - val_accuracy: 0.4762\n","Epoch 294/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 5.0413 - val_accuracy: 0.4762\n","Epoch 295/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 5.0024 - val_accuracy: 0.4762\n","Epoch 296/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 4.9925 - val_accuracy: 0.4762\n","Epoch 297/500\n","6/6 [==============================] - 0s 11ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 5.0097 - val_accuracy: 0.4762\n","Epoch 298/500\n","6/6 [==============================] - 0s 14ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 4.9969 - val_accuracy: 0.4762\n","Epoch 299/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 5.0010 - val_accuracy: 0.4762\n","Epoch 300/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 4.9755 - val_accuracy: 0.4762\n","Epoch 301/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 4.9545 - val_accuracy: 0.4762\n","Epoch 302/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 4.9552 - val_accuracy: 0.4762\n","Epoch 303/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 4.9700 - val_accuracy: 0.4762\n","Epoch 304/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 4.9664 - val_accuracy: 0.4762\n","Epoch 305/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 4.9624 - val_accuracy: 0.4762\n","Epoch 306/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 4.9471 - val_accuracy: 0.4762\n","Epoch 307/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 4.9229 - val_accuracy: 0.4762\n","Epoch 308/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 4.9078 - val_accuracy: 0.4762\n","Epoch 309/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 4.9176 - val_accuracy: 0.4762\n","Epoch 310/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 4.9234 - val_accuracy: 0.4762\n","Epoch 311/500\n","6/6 [==============================] - 0s 18ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 4.9402 - val_accuracy: 0.4762\n","Epoch 312/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 4.9325 - val_accuracy: 0.4762\n","Epoch 313/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 4.9253 - val_accuracy: 0.4762\n","Epoch 314/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 4.9159 - val_accuracy: 0.4762\n","Epoch 315/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 4.8924 - val_accuracy: 0.4762\n","Epoch 316/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 4.8939 - val_accuracy: 0.4762\n","Epoch 317/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 4.9053 - val_accuracy: 0.4762\n","Epoch 318/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 4.9021 - val_accuracy: 0.4762\n","Epoch 319/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 4.9059 - val_accuracy: 0.4762\n","Epoch 320/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 4.8675 - val_accuracy: 0.4762\n","Epoch 321/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 4.8591 - val_accuracy: 0.4762\n","Epoch 322/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 4.8899 - val_accuracy: 0.4762\n","Epoch 323/500\n","6/6 [==============================] - 0s 18ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 4.9050 - val_accuracy: 0.4762\n","Epoch 324/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 4.8981 - val_accuracy: 0.4762\n","Epoch 325/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 4.8864 - val_accuracy: 0.4762\n","Epoch 326/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 4.8862 - val_accuracy: 0.4762\n","Epoch 327/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 4.8995 - val_accuracy: 0.4762\n","Epoch 328/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 4.8731 - val_accuracy: 0.4762\n","Epoch 329/500\n","6/6 [==============================] - 0s 14ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 4.8671 - val_accuracy: 0.4762\n","Epoch 330/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 4.9775 - val_accuracy: 0.4762\n","Epoch 331/500\n","6/6 [==============================] - 0s 20ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 5.1550 - val_accuracy: 0.4762\n","Epoch 332/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 4.9497 - val_accuracy: 0.4762\n","Epoch 333/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 4.8519 - val_accuracy: 0.4762\n","Epoch 334/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 4.8844 - val_accuracy: 0.4762\n","Epoch 335/500\n","6/6 [==============================] - 0s 19ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 4.9696 - val_accuracy: 0.4762\n","Epoch 336/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 5.0296 - val_accuracy: 0.4762\n","Epoch 337/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 5.0344 - val_accuracy: 0.4762\n","Epoch 338/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 4.9678 - val_accuracy: 0.4762\n","Epoch 339/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 4.9420 - val_accuracy: 0.4762\n","Epoch 340/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 4.9315 - val_accuracy: 0.4762\n","Epoch 341/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 4.9325 - val_accuracy: 0.4762\n","Epoch 342/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 4.9489 - val_accuracy: 0.4762\n","Epoch 343/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 4.9609 - val_accuracy: 0.4762\n","Epoch 344/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 4.8994 - val_accuracy: 0.4762\n","Epoch 345/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 4.8627 - val_accuracy: 0.4762\n","Epoch 346/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 4.8637 - val_accuracy: 0.4762\n","Epoch 347/500\n","6/6 [==============================] - 0s 18ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 4.8796 - val_accuracy: 0.4762\n","Epoch 348/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 4.9025 - val_accuracy: 0.4762\n","Epoch 349/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 4.9173 - val_accuracy: 0.4762\n","Epoch 350/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 4.9038 - val_accuracy: 0.4762\n","Epoch 351/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 4.8518 - val_accuracy: 0.4762\n","Epoch 352/500\n","6/6 [==============================] - 0s 14ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 4.8583 - val_accuracy: 0.4762\n","Epoch 353/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 4.8462 - val_accuracy: 0.4762\n","Epoch 354/500\n","6/6 [==============================] - 0s 14ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 4.8378 - val_accuracy: 0.4762\n","Epoch 355/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 4.8573 - val_accuracy: 0.4762\n","Epoch 356/500\n","6/6 [==============================] - 0s 14ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 4.8861 - val_accuracy: 0.4762\n","Epoch 357/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 4.8512 - val_accuracy: 0.4762\n","Epoch 358/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 4.8072 - val_accuracy: 0.4762\n","Epoch 359/500\n","6/6 [==============================] - 0s 17ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 4.8212 - val_accuracy: 0.4762\n","Epoch 360/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 4.8398 - val_accuracy: 0.4762\n","Epoch 361/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 4.8434 - val_accuracy: 0.4762\n","Epoch 362/500\n","6/6 [==============================] - 0s 16ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 4.8359 - val_accuracy: 0.4762\n","Epoch 363/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 4.8371 - val_accuracy: 0.4762\n","Epoch 364/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 4.8306 - val_accuracy: 0.4762\n","Epoch 365/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 4.8473 - val_accuracy: 0.4762\n","Epoch 366/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 4.8612 - val_accuracy: 0.4762\n","Epoch 367/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 4.8321 - val_accuracy: 0.4762\n","Epoch 368/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 4.7897 - val_accuracy: 0.4762\n","Epoch 369/500\n","6/6 [==============================] - 0s 14ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 5.1153 - val_accuracy: 0.4762\n","Epoch 370/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 5.0650 - val_accuracy: 0.4762\n","Epoch 371/500\n","6/6 [==============================] - 0s 14ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 5.0079 - val_accuracy: 0.4762\n","Epoch 372/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 4.9013 - val_accuracy: 0.4762\n","Epoch 373/500\n","6/6 [==============================] - 0s 14ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 4.8825 - val_accuracy: 0.4762\n","Epoch 374/500\n","6/6 [==============================] - 0s 16ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 4.9336 - val_accuracy: 0.4762\n","Epoch 375/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 4.9686 - val_accuracy: 0.4762\n","Epoch 376/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 4.9763 - val_accuracy: 0.4762\n","Epoch 377/500\n","6/6 [==============================] - 0s 16ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 4.9236 - val_accuracy: 0.4762\n","Epoch 378/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 4.8644 - val_accuracy: 0.4762\n","Epoch 379/500\n","6/6 [==============================] - 0s 14ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 4.8533 - val_accuracy: 0.4762\n","Epoch 380/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 4.8719 - val_accuracy: 0.4762\n","Epoch 381/500\n","6/6 [==============================] - 0s 14ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 4.8830 - val_accuracy: 0.4762\n","Epoch 382/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 4.8405 - val_accuracy: 0.4762\n","Epoch 383/500\n","6/6 [==============================] - 0s 17ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 4.8221 - val_accuracy: 0.4762\n","Epoch 384/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 4.8221 - val_accuracy: 0.4762\n","Epoch 385/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 4.8357 - val_accuracy: 0.4762\n","Epoch 386/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 4.8141 - val_accuracy: 0.4762\n","Epoch 387/500\n","6/6 [==============================] - 0s 18ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 4.7843 - val_accuracy: 0.4762\n","Epoch 388/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 4.7883 - val_accuracy: 0.4762\n","Epoch 389/500\n","6/6 [==============================] - 0s 14ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 4.8006 - val_accuracy: 0.4762\n","Epoch 390/500\n","6/6 [==============================] - 0s 15ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 4.8050 - val_accuracy: 0.4762\n","Epoch 391/500\n","6/6 [==============================] - 0s 14ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 4.7661 - val_accuracy: 0.4762\n","Epoch 392/500\n","6/6 [==============================] - 0s 20ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 4.7570 - val_accuracy: 0.4762\n","Epoch 393/500\n","6/6 [==============================] - 0s 14ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 4.7736 - val_accuracy: 0.4762\n","Epoch 394/500\n","6/6 [==============================] - 0s 19ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 4.7796 - val_accuracy: 0.4762\n","Epoch 395/500\n","6/6 [==============================] - 0s 16ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 4.7879 - val_accuracy: 0.4762\n","Epoch 396/500\n","6/6 [==============================] - 0s 15ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 4.7676 - val_accuracy: 0.4762\n","Epoch 397/500\n","6/6 [==============================] - 0s 14ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 4.7387 - val_accuracy: 0.4762\n","Epoch 398/500\n","6/6 [==============================] - 0s 17ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 4.8184 - val_accuracy: 0.4762\n","Epoch 399/500\n","6/6 [==============================] - 0s 15ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 5.1230 - val_accuracy: 0.4762\n","Epoch 400/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 4.9284 - val_accuracy: 0.4762\n","Epoch 401/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 4.7385 - val_accuracy: 0.4762\n","Epoch 402/500\n","6/6 [==============================] - 0s 14ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 4.7950 - val_accuracy: 0.4762\n","Epoch 403/500\n","6/6 [==============================] - 0s 17ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 4.9743 - val_accuracy: 0.4762\n","Epoch 404/500\n","6/6 [==============================] - 0s 16ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 4.9951 - val_accuracy: 0.4762\n","Epoch 405/500\n","6/6 [==============================] - 0s 14ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 4.9095 - val_accuracy: 0.4762\n","Epoch 406/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 4.8342 - val_accuracy: 0.4762\n","Epoch 407/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 4.7987 - val_accuracy: 0.4762\n","Epoch 408/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 4.7992 - val_accuracy: 0.4762\n","Epoch 409/500\n","6/6 [==============================] - 0s 16ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 4.8162 - val_accuracy: 0.4762\n","Epoch 410/500\n","6/6 [==============================] - 0s 14ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 4.8027 - val_accuracy: 0.4762\n","Epoch 411/500\n","6/6 [==============================] - 0s 16ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 4.7676 - val_accuracy: 0.4762\n","Epoch 412/500\n","6/6 [==============================] - 0s 14ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 4.7738 - val_accuracy: 0.4762\n","Epoch 413/500\n","6/6 [==============================] - 0s 17ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 4.7709 - val_accuracy: 0.4762\n","Epoch 414/500\n","6/6 [==============================] - 0s 18ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 4.7533 - val_accuracy: 0.4762\n","Epoch 415/500\n","6/6 [==============================] - 0s 20ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 4.7234 - val_accuracy: 0.4762\n","Epoch 416/500\n","6/6 [==============================] - 0s 17ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 4.7183 - val_accuracy: 0.4762\n","Epoch 417/500\n","6/6 [==============================] - 0s 18ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 4.7237 - val_accuracy: 0.4762\n","Epoch 418/500\n","6/6 [==============================] - 0s 14ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 4.7476 - val_accuracy: 0.4762\n","Epoch 419/500\n","6/6 [==============================] - 0s 17ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 4.7547 - val_accuracy: 0.4762\n","Epoch 420/500\n","6/6 [==============================] - 0s 18ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 4.7161 - val_accuracy: 0.4762\n","Epoch 421/500\n","6/6 [==============================] - 0s 14ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 4.7049 - val_accuracy: 0.4762\n","Epoch 422/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 4.6846 - val_accuracy: 0.4762\n","Epoch 423/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 4.6975 - val_accuracy: 0.4762\n","Epoch 424/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 4.7126 - val_accuracy: 0.4762\n","Epoch 425/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 4.7134 - val_accuracy: 0.4762\n","Epoch 426/500\n","6/6 [==============================] - 0s 17ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 4.6999 - val_accuracy: 0.4762\n","Epoch 427/500\n","6/6 [==============================] - 0s 15ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 4.6817 - val_accuracy: 0.4762\n","Epoch 428/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 4.8215 - val_accuracy: 0.4762\n","Epoch 429/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 4.9682 - val_accuracy: 0.4762\n","Epoch 430/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 4.6854 - val_accuracy: 0.4762\n","Epoch 431/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 4.6492 - val_accuracy: 0.4762\n","Epoch 432/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 4.8414 - val_accuracy: 0.4762\n","Epoch 433/500\n","6/6 [==============================] - 0s 14ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 4.9015 - val_accuracy: 0.4762\n","Epoch 434/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 4.8746 - val_accuracy: 0.4762\n","Epoch 435/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 4.7110 - val_accuracy: 0.4762\n","Epoch 436/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 4.6687 - val_accuracy: 0.4762\n","Epoch 437/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 4.6903 - val_accuracy: 0.4762\n","Epoch 438/500\n","6/6 [==============================] - 0s 18ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 4.7327 - val_accuracy: 0.4762\n","Epoch 439/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 4.7346 - val_accuracy: 0.4762\n","Epoch 440/500\n","6/6 [==============================] - 0s 14ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 4.6955 - val_accuracy: 0.4762\n","Epoch 441/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 4.6732 - val_accuracy: 0.4762\n","Epoch 442/500\n","6/6 [==============================] - 0s 16ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 4.6683 - val_accuracy: 0.4762\n","Epoch 443/500\n","6/6 [==============================] - 0s 14ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 4.6738 - val_accuracy: 0.4762\n","Epoch 444/500\n","6/6 [==============================] - 0s 17ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 4.6419 - val_accuracy: 0.4762\n","Epoch 445/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 4.6663 - val_accuracy: 0.4762\n","Epoch 446/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 4.6300 - val_accuracy: 0.4762\n","Epoch 447/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 4.6321 - val_accuracy: 0.4762\n","Epoch 448/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 4.6465 - val_accuracy: 0.4762\n","Epoch 449/500\n","6/6 [==============================] - 0s 19ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 4.6704 - val_accuracy: 0.4762\n","Epoch 450/500\n","6/6 [==============================] - 0s 17ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 4.6439 - val_accuracy: 0.4762\n","Epoch 451/500\n","6/6 [==============================] - 0s 15ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 4.7616 - val_accuracy: 0.4762\n","Epoch 452/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 4.9183 - val_accuracy: 0.4762\n","Epoch 453/500\n","6/6 [==============================] - 0s 19ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 4.6837 - val_accuracy: 0.4762\n","Epoch 454/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 4.6385 - val_accuracy: 0.4762\n","Epoch 455/500\n","6/6 [==============================] - 0s 14ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 4.8581 - val_accuracy: 0.4762\n","Epoch 456/500\n","6/6 [==============================] - 0s 19ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 4.8476 - val_accuracy: 0.4762\n","Epoch 457/500\n","6/6 [==============================] - 0s 17ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 4.6965 - val_accuracy: 0.4762\n","Epoch 458/500\n","6/6 [==============================] - 0s 19ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 4.6373 - val_accuracy: 0.4762\n","Epoch 459/500\n","6/6 [==============================] - 0s 20ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 4.6649 - val_accuracy: 0.4762\n","Epoch 460/500\n","6/6 [==============================] - 0s 18ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 4.6977 - val_accuracy: 0.4762\n","Epoch 461/500\n","6/6 [==============================] - 0s 18ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 4.6746 - val_accuracy: 0.4762\n","Epoch 462/500\n","6/6 [==============================] - 0s 19ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 4.6385 - val_accuracy: 0.4762\n","Epoch 463/500\n","6/6 [==============================] - 0s 19ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 4.6060 - val_accuracy: 0.4762\n","Epoch 464/500\n","6/6 [==============================] - 0s 14ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 4.6250 - val_accuracy: 0.4762\n","Epoch 465/500\n","6/6 [==============================] - 0s 19ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 4.6452 - val_accuracy: 0.4762\n","Epoch 466/500\n","6/6 [==============================] - 0s 16ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 4.6136 - val_accuracy: 0.4762\n","Epoch 467/500\n","6/6 [==============================] - 0s 17ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 4.5850 - val_accuracy: 0.4762\n","Epoch 468/500\n","6/6 [==============================] - 0s 16ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 4.6352 - val_accuracy: 0.4762\n","Epoch 469/500\n","6/6 [==============================] - 0s 20ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 4.6290 - val_accuracy: 0.4762\n","Epoch 470/500\n","6/6 [==============================] - 0s 18ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 4.6050 - val_accuracy: 0.4762\n","Epoch 471/500\n","6/6 [==============================] - 0s 20ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 4.5894 - val_accuracy: 0.4762\n","Epoch 472/500\n","6/6 [==============================] - 0s 18ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 4.7266 - val_accuracy: 0.4762\n","Epoch 473/500\n","6/6 [==============================] - 0s 18ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 4.8776 - val_accuracy: 0.4762\n","Epoch 474/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 4.6944 - val_accuracy: 0.4762\n","Epoch 475/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 4.6464 - val_accuracy: 0.4762\n","Epoch 476/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 4.7706 - val_accuracy: 0.4762\n","Epoch 477/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 4.7472 - val_accuracy: 0.4762\n","Epoch 478/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 4.7125 - val_accuracy: 0.4762\n","Epoch 479/500\n","6/6 [==============================] - 0s 15ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 4.6413 - val_accuracy: 0.4762\n","Epoch 480/500\n","6/6 [==============================] - 0s 16ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 4.6666 - val_accuracy: 0.4762\n","Epoch 481/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 4.6684 - val_accuracy: 0.4762\n","Epoch 482/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 4.6247 - val_accuracy: 0.4762\n","Epoch 483/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 4.6154 - val_accuracy: 0.4762\n","Epoch 484/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 4.5875 - val_accuracy: 0.4762\n","Epoch 485/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 4.6003 - val_accuracy: 0.4762\n","Epoch 486/500\n","6/6 [==============================] - 0s 15ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 4.5630 - val_accuracy: 0.4762\n","Epoch 487/500\n","6/6 [==============================] - 0s 14ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 4.5673 - val_accuracy: 0.4762\n","Epoch 488/500\n","6/6 [==============================] - 0s 14ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 4.5882 - val_accuracy: 0.4762\n","Epoch 489/500\n","6/6 [==============================] - 0s 16ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 4.5871 - val_accuracy: 0.4762\n","Epoch 490/500\n","6/6 [==============================] - 0s 17ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 4.5535 - val_accuracy: 0.4762\n","Epoch 491/500\n","6/6 [==============================] - 0s 19ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 4.5623 - val_accuracy: 0.4762\n","Epoch 492/500\n","6/6 [==============================] - 0s 16ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 4.5496 - val_accuracy: 0.4762\n","Epoch 493/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 4.8110 - val_accuracy: 0.4762\n","Epoch 494/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 4.6672 - val_accuracy: 0.4762\n","Epoch 495/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 4.6517 - val_accuracy: 0.4762\n","Epoch 496/500\n","6/6 [==============================] - 0s 14ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 4.7254 - val_accuracy: 0.4762\n","Epoch 497/500\n","6/6 [==============================] - 0s 14ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 4.7555 - val_accuracy: 0.4762\n","Epoch 498/500\n","6/6 [==============================] - 0s 12ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 4.6372 - val_accuracy: 0.4762\n","Epoch 499/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 4.5942 - val_accuracy: 0.4762\n","Epoch 500/500\n","6/6 [==============================] - 0s 13ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 4.6378 - val_accuracy: 0.4762\n"]},{"output_type":"execute_result","data":{"text/plain":["<matplotlib.legend.Legend at 0x7f3e57fba810>"]},"metadata":{},"execution_count":101},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 360x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":["After the training, we can evaluate the regularized NN use the following command. "],"metadata":{"id":"1WOoKagyPudE"}},{"cell_type":"code","source":["cat_model_regu.evaluate(test_x,test_y)"],"metadata":{"id":"YXZxD8R-P78E","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1643597691167,"user_tz":300,"elapsed":173,"user":{"displayName":"Ahmad Alshami","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01911245819879647322"}},"outputId":"0443fb44-310f-4ecd-a82b-3a26c0bd0b6e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2/2 [==============================] - 0s 7ms/step - loss: 3.5118 - accuracy: 0.6400\n"]},{"output_type":"execute_result","data":{"text/plain":["[3.5118279457092285, 0.6399999856948853]"]},"metadata":{},"execution_count":102}]},{"cell_type":"markdown","source":["The expected accuracy is highter than 0.8. "],"metadata":{"id":"o1IED5YNP7GM"}}]}